{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Tree Model with XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from xgboost import plot_tree\n",
    "from xgboost import to_graphviz\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import numpy as np\n",
    "import graphviz\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../../Data/preprocessed_X_train.csv\", index_col=\"respondent_id\")\n",
    "X_test = pd.read_csv(\"../../Data/preprocessed_X_test.csv\", index_col=\"respondent_id\")\n",
    "y_train = pd.read_csv(\"../../Data/preprocessed_y_train.csv\", index_col=\"respondent_id\")\n",
    "y_test = pd.read_csv(\"../../Data/preprocessed_y_test.csv\", index_col=\"respondent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Espacio de búsqueda de hiperparámetros\n",
    "search_space = {\n",
    "    'estimator__max_depth': Integer(3, 20),  # Aumentar profundidad máxima del árbol\n",
    "    'estimator__learning_rate': Real(0.001, 0.3, prior='log-uniform'),  # Ampliar rango del learning rate\n",
    "    'estimator__subsample': Real(0.3, 1.0),  # Permitir tamaños de muestra más pequeños\n",
    "    'estimator__colsample_bytree': Real(0.3, 1.0),  # Más flexibilidad en columnas seleccionadas\n",
    "    'estimator__n_estimators': Integer(50, 500),  # Incrementar número máximo de árboles\n",
    "    'estimator__gamma': Real(0.0, 10.0),  # Permitir mayor regularización\n",
    "    'estimator__min_child_weight': Integer(1, 10),  # Considerar pesos mínimos para evitar sobreajuste\n",
    "    'estimator__reg_alpha': Real(0.0, 1.0),  # Regularización L1\n",
    "    'estimator__reg_lambda': Real(0.0, 1.0)  # Regularización L2\n",
    "}\n",
    "\n",
    "# Crear el modelo base\n",
    "xgb_model = XGBClassifier(eval_metric='auc', random_state=42)\n",
    "\n",
    "# Envolverlo en MultiOutputClassifier para predicción multietiqueta\n",
    "multi_xgb = MultiOutputClassifier(xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: OrderedDict({'estimator__colsample_bytree': 0.9923319362435739, 'estimator__gamma': 0.20432997478467166, 'estimator__learning_rate': 0.018830734677431557, 'estimator__max_depth': 5, 'estimator__min_child_weight': 5, 'estimator__n_estimators': 494, 'estimator__reg_alpha': 0.3347004937222214, 'estimator__reg_lambda': 0.9746608636023493, 'estimator__subsample': 0.37139687975992147})\n",
      "Mejor puntaje (AUROC): 0.8658933293740831\n",
      "Modelo guardado como 'XGBoost_best_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Configurar BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    multi_xgb,\n",
    "    search_space,\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con optimización\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros:\", opt.best_params_)\n",
    "print(\"Mejor puntaje (AUROC):\", opt.best_score_)\n",
    "\n",
    "# Guardar el mejor modelo optimizado\n",
    "joblib.dump(opt.best_estimator_, \"Modelos/XGBoost_best_model.pkl\")\n",
    "print(\"Modelo guardado como 'XGBoost_best_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           feature  importance\n",
      "84                doctor_recc_h1n1    0.116306\n",
      "112    health_insurance_is_missing    0.039825\n",
      "89                health_insurance    0.031491\n",
      "90     opinion_h1n1_vacc_effective    0.028797\n",
      "91               opinion_h1n1_risk    0.026262\n",
      "..                             ...         ...\n",
      "39    employment_industry_qnlwzans    0.000000\n",
      "37    employment_industry_phxvnwax    0.000000\n",
      "35    employment_industry_msuufmds    0.000000\n",
      "29    employment_industry_dotnnunm    0.000000\n",
      "120  household_children_is_missing    0.000000\n",
      "\n",
      "[121 rows x 2 columns]\n",
      "Características seleccionadas (95): ['doctor_recc_h1n1', 'health_insurance_is_missing', 'health_insurance', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk', 'employment_industry_haxffmxo', 'health_worker', 'opinion_h1n1_sick_from_vacc_is_missing', 'employment_industry_fcxhlnwr', 'opinion_seas_risk', 'employment_occupation_cmhcxjea', 'employment_occupation_haliazsg', 'doctor_recc_seasonal', 'marital_status_Missing', 'race_Black', 'child_under_6_months', 'employment_occupation_tfqavkke', 'rent_or_own_Missing', 'employment_industry_arjwrbjb', 'behavioral_face_mask', 'employment_occupation_dlvbwzss', 'employment_occupation_kldqjyjy', 'behavioral_antiviral_meds', 'hhs_geo_region_mlyzmhmf', 'employment_occupation_rcertsgn', 'h1n1_knowledge', 'employment_occupation_dcjcmpih', 'employment_industry_mfikgejo', 'employment_occupation_xgwztkwe', 'race_Other or Multiple', 'opinion_seas_vacc_effective', 'employment_occupation_uqqtjvyb', 'employment_occupation_oijqvulv', 'hhs_geo_region_oxchjgsf', 'employment_occupation_mxkfnird', 'age_group', 'employment_occupation_hfxkjkmi', 'employment_industry_cfqqtusy', 'employment_industry_xqicxuve', 'employment_industry_ldnlellj', 'employment_industry_pxcmvdjn', 'employment_industry_atmlpfrs', 'opinion_seas_sick_from_vacc', 'education', 'employment_industry_wxleyezf', 'employment_industry_xicduogh', 'hhs_geo_region_lzgpxyit', 'hhs_geo_region_dqpwygqj', 'h1n1_concern', 'race_White', 'employment_occupation_xtkaffoo', 'race_Hispanic', 'employment_occupation_hodpvpew', 'employment_occupation_Missing', 'employment_industry_mcubkhph', 'employment_industry_saaquncn', 'sex_Female', 'rent_or_own_Rent', 'opinion_h1n1_sick_from_vacc', 'employment_status', 'census_msa_Non-MSA', 'hhs_geo_region_bhuqouqj', 'chronic_med_condition', 'marital_status_Not Married', 'hhs_geo_region_qufhixun', 'behavioral_wash_hands', 'employment_occupation_qxajmpny', 'hhs_geo_region_atmpeygn', 'income_poverty', 'rent_or_own_Own', 'household_adults', 'hhs_geo_region_lrircsnp', 'hhs_geo_region_fpwskwrf', 'employment_industry_nduyfdeo', 'employment_occupation_bxpfxfdn', 'employment_occupation_xqwwgdyp', 'household_children', 'employment_industry_wlfvacwt', 'employment_industry_rucpziij', 'behavioral_touch_face', 'hhs_geo_region_kbazzjca', 'employment_occupation_vlluhbov', 'employment_industry_vjjrobsf', 'behavioral_large_gatherings', 'census_msa_MSA, Principle City', 'behavioral_outside_home', 'employment_occupation_emcorrxb', 'behavioral_avoidance', 'employment_occupation_ccgxvspp', 'employment_industry_Missing', 'employment_occupation_ukymxvdu', 'employment_occupation_xzmlyyjv', 'marital_status_Married', 'census_msa_MSA, Not Principle  City', 'sex_Male']\n"
     ]
    }
   ],
   "source": [
    "# Obtener la importancia de las características del modelo base\n",
    "model_base = opt.best_estimator_.estimators_[0] \n",
    "feature_importances = model_base.feature_importances_\n",
    "\n",
    "# Crear un DataFrame para visualizar la importancia\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': feature_importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Mostrar las características más importantes\n",
    "print(importance_df)\n",
    "\n",
    "# Establecer un umbral (por ejemplo, 0.001) para filtrar características poco importantes\n",
    "threshold = 0.001\n",
    "important_features = importance_df[importance_df['importance'] > threshold]['feature'].tolist()\n",
    "\n",
    "print(f\"Características seleccionadas ({len(important_features)}):\", important_features)\n",
    "\n",
    "# Filtrar el conjunto de datos con las características seleccionadas\n",
    "X_train_filtered = X_train[important_features]\n",
    "X_test_filtered = X_test[important_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m      8\u001b[0m opt2 \u001b[38;5;241m=\u001b[39m BayesSearchCV(\n\u001b[0;32m      9\u001b[0m     multi_xgb,\n\u001b[0;32m     10\u001b[0m     search_space,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     16\u001b[0m )\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con optimización\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mopt2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Mostrar los mejores hiperparámetros\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMejores hiperparámetros:\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt2\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\skopt\\searchcv.py:542\u001b[0m, in \u001b[0;36mBayesSearchCV.fit\u001b[1;34m(self, X, y, groups, callback, **fit_params)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrefit):\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    537\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBayesSearchCV doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support a callable refit, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt define an implicit score to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    540\u001b[0m     )\n\u001b[1;32m--> 542\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# BaseSearchCV never ranked train scores,\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# but apparently we used to ship this (back-compat)\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_train_score:\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1020\u001b[0m     )\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\skopt\\searchcv.py:599\u001b[0m, in \u001b[0;36mBayesSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m    595\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_iter \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# when n_iter < n_points points left for evaluation\u001b[39;00m\n\u001b[0;32m    597\u001b[0m     n_points_adjusted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_iter, n_points)\n\u001b[1;32m--> 599\u001b[0m     optim_result, score_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43msearch_space\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_points\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_points_adjusted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m     n_iter \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m n_points\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\skopt\\searchcv.py:453\u001b[0m, in \u001b[0;36mBayesSearchCV._step\u001b[1;34m(self, search_space, optimizer, score_name, evaluate_candidates, n_points)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# make lists into dictionaries\u001b[39;00m\n\u001b[0;32m    451\u001b[0m params_dict \u001b[38;5;241m=\u001b[39m [point_asdict(search_space, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m params]\n\u001b[1;32m--> 453\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# if self.scoring is a callable, we have to wait until here\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;66;03m# to get the score name\u001b[39;00m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m score_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    967\u001b[0m         )\n\u001b[0;32m    968\u001b[0m     )\n\u001b[1;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m     )\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Crear el modelo base\n",
    "xgb_model2 = XGBClassifier(eval_metric='auc', random_state=42)\n",
    "\n",
    "# Envolverlo en MultiOutputClassifier para predicción multietiqueta\n",
    "multi_xgb2 = MultiOutputClassifier(xgb_model2)\n",
    "\n",
    "# Configurar BayesSearchCV\n",
    "opt2 = BayesSearchCV(\n",
    "    multi_xgb,\n",
    "    search_space,\n",
    "    cv=5,\n",
    "    n_iter=50,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con optimización\n",
    "opt2.fit(X_train_filtered, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros:\", opt2.best_params_)\n",
    "print(\"Mejor puntaje (AUROC):\", opt2.best_score_)\n",
    "\n",
    "# Guardar el mejor modelo optimizado\n",
    "# joblib.dump(opt2.best_estimator_, \"Modelos/XGBoost_best_model.pkl\")\n",
    "# print(\"Modelo guardado como 'XGBoost_best_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC para H1N1: 0.8777441415555572\n",
      "AUROC para vacuna estacional: 0.8646201134753051\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.53      0.61      1135\n",
      "           1       0.79      0.76      0.77      2488\n",
      "\n",
      "   micro avg       0.77      0.69      0.73      3623\n",
      "   macro avg       0.76      0.64      0.69      3623\n",
      "weighted avg       0.77      0.69      0.72      3623\n",
      " samples avg       0.35      0.34      0.34      3623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\USERS\\PABLO\\ONEDRIVE\\DOCUMENTOS\\ESTUDIOS\\DATCOM\\1ER CUATRIMESTRE\\MINERÍA DE DATOS. PREPROCESAMIENTO Y CLASIFICACIÓN\\FLUSHOTLEARNING\\VENV\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Predicción\n",
    "y_pred = opt.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calcular probabilidades para AUROC\n",
    "y_proba = opt.best_estimator_.predict_proba(X_test)\n",
    "\n",
    "# Convertir las probabilidades a un DataFrame para cada etiqueta\n",
    "y_proba_h1n1 = y_proba[0][:, 1]  # Para H1N1\n",
    "y_proba_seasonal = y_proba[1][:, 1]  # Para vacuna estacional\n",
    "\n",
    "# Extraer las etiquetas reales como arrays 1D\n",
    "y_test_h1n1 = y_test.iloc[:, 0].values  # H1N1\n",
    "y_test_seasonal = y_test.iloc[:, 1].values  # Vacuna estacional\n",
    "\n",
    "# AUROC para cada etiqueta\n",
    "roc_auc_h1n1 = roc_auc_score(y_test_h1n1, y_proba_h1n1)\n",
    "roc_auc_seasonal = roc_auc_score(y_test_seasonal, y_proba_seasonal)\n",
    "\n",
    "print(f\"AUROC para H1N1: {roc_auc_h1n1}\")\n",
    "print(f\"AUROC para vacuna estacional: {roc_auc_seasonal}\")\n",
    "\n",
    "# Informe de clasificación\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'XGBoost_submission.csv' generado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset de prueba preprocesado\n",
    "test_set_preprocessed = pd.read_csv(\"../../Data/preprocessed_test_set_features.csv\")\n",
    "\n",
    "# Asegurarse de que respondent_id esté disponible\n",
    "respondent_ids = test_set_preprocessed['respondent_id']\n",
    "\n",
    "# Eliminar respondent_id del conjunto de características\n",
    "X_test_final = test_set_preprocessed.drop(columns=['respondent_id'])\n",
    "\n",
    "# Realizar predicciones de probabilidad\n",
    "y_proba_test = opt.best_estimator_.predict_proba(X_test_final)\n",
    "\n",
    "# Extraer las probabilidades para la clase positiva (1)\n",
    "y_proba_h1n1_test = y_proba_test[0][:, 1]  # Probabilidades para H1N1\n",
    "y_proba_seasonal_test = y_proba_test[1][:, 1]  # Probabilidades para vacuna estacional\n",
    "\n",
    "# Crear el DataFrame de submission\n",
    "submission = pd.DataFrame({\n",
    "    \"respondent_id\": respondent_ids,\n",
    "    \"h1n1_vaccine\": y_proba_h1n1_test,\n",
    "    \"seasonal_vaccine\": y_proba_seasonal_test\n",
    "})\n",
    "\n",
    "# Guardar el archivo de submission\n",
    "submission.to_csv(\"Submissions/XGBoost_submission.csv\", index=False)\n",
    "print(\"Archivo 'XGBoost_submission.csv' generado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de carga de modelo guardado para su posterior uso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el modelo guardado\n",
    "loaded_model = joblib.load(\"Modelos/XGBoost_best_model.pkl\")\n",
    "print(\"Modelo cargado correctamente.\")\n",
    "\n",
    "# Realizar predicciones usando el modelo cargado\n",
    "y_proba_test = loaded_model.predict_proba(X_test_final)\n",
    "\n",
    "# Extraer probabilidades para cada etiqueta\n",
    "y_proba_h1n1_test = y_proba_test[0][:, 1]  # Probabilidades para H1N1\n",
    "y_proba_seasonal_test = y_proba_test[1][:, 1]  # Probabilidades para vacuna estacional\n",
    "\n",
    "# Crear un DataFrame para la submission si es necesario\n",
    "submission = pd.DataFrame({\n",
    "    \"respondent_id\": respondent_ids,\n",
    "    \"h1n1_vaccine\": y_proba_h1n1_test,\n",
    "    \"seasonal_vaccine\": y_proba_seasonal_test\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
