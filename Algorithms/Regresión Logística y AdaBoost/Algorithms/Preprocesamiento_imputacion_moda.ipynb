{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flu Shot Learning: Predict H1N1 and Seasonal Flu Vaccines\n",
    "\n",
    "------------------------------------------------------\n",
    "*Pablo Gradolph Oliva*\n",
    "\n",
    "*Jaime De Castro Escribano*\n",
    "\n",
    "*Enric*\n",
    "\n",
    "*Adrián*\n",
    "\n",
    "*Ruxandra Cojocaru*\n",
    "\n",
    "------------------------------------------------------\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Nuestro objetivo es predecir la probabilidad de que las personas reciban las vacunas contra la gripe H1N1 y la gripe estacional. Específicamente, debemos predecir dos probabilidades: una para la vacuna contra la gripe H1N1 y otra para la vacuna contra la gripe estacional.\n",
    "\n",
    "Cada fila del conjunto de datos representa a una persona que respondió a la Encuesta nacional sobre la gripe H1N1 2009.\n",
    "\n",
    "Para esta competición, hay dos variables objetivo:\n",
    "\n",
    "    - h1n1_vaccine: Si el encuestado recibió la vacuna contra la gripe H1N1.\n",
    "    - seasonal_vaccine: Si el encuestado recibió la vacuna contra la gripe estacional.\n",
    "\n",
    "Ambas son variables binarias: 0 = No; 1 = Sí. Algunos encuestados no recibieron ninguna de las vacunas, otros recibieron sólo una y algunos recibieron ambas. Esto se formula como un problema multietiqueta (y no multiclase).\n",
    "\n",
    "Se proporciona un conjunto de datos con 36 columnas. La primera columna respondent_id es un identificador único y aleatorio. Las 35 características restantes se describen a continuación. Para todas las variables binarias: 0 = No; 1 = Sí.\n",
    "\n",
    "    - h1n1_concern: Nivel de preocupación por la gripe H1N1.\n",
    "    0 = Nada preocupado; 1 = Poco preocupado; 2 = Algo preocupado; 3 = Muy preocupado.\n",
    "    - h1n1_knowledge: Nivel de conocimiento sobre la gripe H1N1.\n",
    "    0 = Ningún conocimiento; 1 = Poco conocimiento; 2 = Mucho conocimiento.\n",
    "    - behavioral_antiviral_meds: Ha tomado medicamentos antivirales. (binario)\n",
    "    - behavioral_avoidance - Ha evitado el contacto cercano con otras personas con síntomas gripales. (binario)\n",
    "    - behavioral_face_mask: Se ha comprado una mascarilla facial. (binario)\n",
    "    - behavioral_wash_hands: Se ha lavado las manos con frecuencia o ha utilizado desinfectante para manos. (binario)\n",
    "    - behavioral_large_gatherings: Ha reducido el tiempo dedicado a las grandes reuniones. (binario)\n",
    "    - behavioral_outside_home: Ha reducido el contacto con personas ajenas a su hogar. (binario)\n",
    "    - behavioral_touch_face: Ha evitado tocarse los ojos, la nariz o la boca. (binario)\n",
    "    - doctor_recc_h1n1: El médico recomendó la vacuna contra la gripe H1N1. (binario)\n",
    "    - doctor_recc_seasonal: El médico recomendó la vacuna contra la gripe estacional. (binario)\n",
    "    - chronic_med_condition: Padece alguna de las siguientes afecciones crónicas: asma u otra afección pulmonar, diabetes, afección cardíaca, afección renal, anemia falciforme u otra anemia, afección neurológica o neuromuscular, afección hepática o debilidad del sistema inmunitario causada por una enfermedad crónica o por los medicamentos que toma para una enfermedad crónica. (binario)\n",
    "    - child_under_6_months: Tiene contacto regular con un niño menor de seis meses. (binario)\n",
    "    - health_worker: Es un trabajador sanitario. (binario)\n",
    "    - health_insurance: Tiene seguro médico. (binario)\n",
    "    - opinion_h1n1_vacc_effective: Opinión del encuestado sobre la eficacia de la vacuna contra la gripe H1N1.\n",
    "    1 = Nada eficaz; 2 = Poco eficaz; 3 = No lo sé; 4 = Algo eficaz; 5 = Muy eficaz.\n",
    "    - opinion_h1n1_risk: Opinión del encuestado sobre el riesgo de contraer la gripe H1N1 sin vacunarse.\n",
    "    1 = Muy bajo; 2 = Algo bajo; 3 = No lo sé; 4 = Algo alto; 5 = Muy alto.\n",
    "    - opinion_h1n1_sick_from_vacc: Preocupación del encuestado de enfermar por vacunarse contra la gripe H1N1.\n",
    "    1 = Nada preocupado; 2 = Poco preocupado; 3 = No lo sé; 4 = Algo preocupado; 5 = Muy preocupado.\n",
    "    - opinion_seas_vacc_effective: Opinión del encuestado sobre la eficacia de la vacuna contra la gripe estacional.\n",
    "    1 = Nada eficaz; 2 = Poco eficaz; 3 = No lo sé; 4 = Algo eficaz; 5 = Muy eficaz.\n",
    "    - opinion_seas_risk: Opinión del encuestado sobre el riesgo de contraer la gripe de temporada sin vacunarse.\n",
    "    1 = Muy baja; 2 = Algo baja; 3 = No lo sé; 4 = Algo alta; 5 = Muy alta.\n",
    "    - opinion_seas_ick_from_vacc: Preocupación del encuestado de enfermar por vacunarse contra la gripe estacional.\n",
    "    1 = Nada preocupado; 2 = Poco preocupado; 3 = No lo sé; 4 = Algo preocupado; 5 = Muy preocupado.\n",
    "    - age_group: Grupo de edad del encuestado.\n",
    "    - education: Nivel de estudios declarado por el encuestado.\n",
    "    - race: Raza del encuestado.\n",
    "    - sex: Sexo del encuestado.\n",
    "    - income_poverty: Ingresos anuales del hogar del encuestado con respecto a los umbrales de pobreza del censo de 2008.\n",
    "    - marital_status: Estado civil del encuestado.\n",
    "    - rent_or_own: Situación de vivienda del encuestado.\n",
    "    - employment_status: Situación laboral del encuestado.\n",
    "    - hhs_geo_region: Residencia del encuestado según una clasificación geográfica de 10 regiones definida por el Departamento de Salud y Servicios Humanos de EE.UU.. Los valores se representan como cadenas cortas de caracteres aleatorios.\n",
    "    - census_msa: Residencia del encuestado dentro de las áreas estadísticas metropolitanas (MSA) definidas por el Censo de EE.UU.\n",
    "    - household_adults: Número de otros adultos en el hogar, con un código máximo de 3.\n",
    "    - household_children: Número de niños en el hogar, codificado hasta 3.\n",
    "    - employment_industry: Tipo de sector en el que trabaja el encuestado. Los valores se representan como cadenas cortas de caracteres aleatorios.\n",
    "    - employment_occupation: Tipo de ocupación del encuestado. Los valores se representan como cadenas cortas de caracteres aleatorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Análisis exploratorio de datos y preprocesamiento del dataset\n",
    "\n",
    "Vamos a realizar el análisis exploratorio de datos y el preprocesamiento para poder llevar a cabo el trabajo. Para ello empezamos cargando el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('../Data/training_set_features.csv', index_col=\"respondent_id\")\n",
    "y = pd.read_csv(\"../Data/training_set_labels.csv\", index_col=\"respondent_id\", usecols=[\"respondent_id\", \"h1n1_vaccine\", \"seasonal_vaccine\"])\n",
    "\n",
    "# Cargar el dataset de prueba para aplicarle el mismo preprocesamiento\n",
    "test_set_features_submission = pd.read_csv(\"../Data/test_set_features.csv\", index_col=\"respondent_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "df = X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las dimensiones. Y algunas características clave del dataset para una primera aproximación al mismo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas: 21365, Columnas: 35\n"
     ]
    }
   ],
   "source": [
    "print(f'Filas: {df.shape[0]}, Columnas: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21365 entries, 12230 to 467\n",
      "Data columns (total 35 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   h1n1_concern                 21292 non-null  float64\n",
      " 1   h1n1_knowledge               21275 non-null  float64\n",
      " 2   behavioral_antiviral_meds    21308 non-null  float64\n",
      " 3   behavioral_avoidance         21197 non-null  float64\n",
      " 4   behavioral_face_mask         21351 non-null  float64\n",
      " 5   behavioral_wash_hands        21333 non-null  float64\n",
      " 6   behavioral_large_gatherings  21294 non-null  float64\n",
      " 7   behavioral_outside_home      21300 non-null  float64\n",
      " 8   behavioral_touch_face        21269 non-null  float64\n",
      " 9   doctor_recc_h1n1             19647 non-null  float64\n",
      " 10  doctor_recc_seasonal         19647 non-null  float64\n",
      " 11  chronic_med_condition        20597 non-null  float64\n",
      " 12  child_under_6_months         20699 non-null  float64\n",
      " 13  health_worker                20716 non-null  float64\n",
      " 14  health_insurance             11558 non-null  float64\n",
      " 15  opinion_h1n1_vacc_effective  21039 non-null  float64\n",
      " 16  opinion_h1n1_risk            21049 non-null  float64\n",
      " 17  opinion_h1n1_sick_from_vacc  21042 non-null  float64\n",
      " 18  opinion_seas_vacc_effective  20993 non-null  float64\n",
      " 19  opinion_seas_risk            20947 non-null  float64\n",
      " 20  opinion_seas_sick_from_vacc  20933 non-null  float64\n",
      " 21  age_group                    21365 non-null  object \n",
      " 22  education                    20238 non-null  object \n",
      " 23  race                         21365 non-null  object \n",
      " 24  sex                          21365 non-null  object \n",
      " 25  income_poverty               17835 non-null  object \n",
      " 26  marital_status               20243 non-null  object \n",
      " 27  rent_or_own                  19746 non-null  object \n",
      " 28  employment_status            20193 non-null  object \n",
      " 29  hhs_geo_region               21365 non-null  object \n",
      " 30  census_msa                   21365 non-null  object \n",
      " 31  household_adults             21162 non-null  float64\n",
      " 32  household_children           21162 non-null  float64\n",
      " 33  employment_industry          10758 non-null  object \n",
      " 34  employment_occupation        10649 non-null  object \n",
      "dtypes: float64(23), object(12)\n",
      "memory usage: 5.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       h1n1_concern  h1n1_knowledge  behavioral_antiviral_meds  \\\n",
      "count  21292.000000    21275.000000               21308.000000   \n",
      "mean       1.617462        1.262280                   0.049183   \n",
      "std        0.911139        0.617598                   0.216256   \n",
      "min        0.000000        0.000000                   0.000000   \n",
      "25%        1.000000        1.000000                   0.000000   \n",
      "50%        2.000000        1.000000                   0.000000   \n",
      "75%        2.000000        2.000000                   0.000000   \n",
      "max        3.000000        2.000000                   1.000000   \n",
      "\n",
      "       behavioral_avoidance  behavioral_face_mask  behavioral_wash_hands  \\\n",
      "count          21197.000000          21351.000000           21333.000000   \n",
      "mean               0.725905              0.070489               0.825247   \n",
      "std                0.446068              0.255974               0.379764   \n",
      "min                0.000000              0.000000               0.000000   \n",
      "25%                0.000000              0.000000               1.000000   \n",
      "50%                1.000000              0.000000               1.000000   \n",
      "75%                1.000000              0.000000               1.000000   \n",
      "max                1.000000              1.000000               1.000000   \n",
      "\n",
      "       behavioral_large_gatherings  behavioral_outside_home  \\\n",
      "count                 21294.000000             21300.000000   \n",
      "mean                      0.355875                 0.334413   \n",
      "std                       0.478789                 0.471796   \n",
      "min                       0.000000                 0.000000   \n",
      "25%                       0.000000                 0.000000   \n",
      "50%                       0.000000                 0.000000   \n",
      "75%                       1.000000                 1.000000   \n",
      "max                       1.000000                 1.000000   \n",
      "\n",
      "       behavioral_touch_face  doctor_recc_h1n1  ...  health_worker  \\\n",
      "count           21269.000000      19647.000000  ...   20716.000000   \n",
      "mean                0.675866          0.219423  ...       0.112667   \n",
      "std                 0.468061          0.413866  ...       0.316192   \n",
      "min                 0.000000          0.000000  ...       0.000000   \n",
      "25%                 0.000000          0.000000  ...       0.000000   \n",
      "50%                 1.000000          0.000000  ...       0.000000   \n",
      "75%                 1.000000          0.000000  ...       0.000000   \n",
      "max                 1.000000          1.000000  ...       1.000000   \n",
      "\n",
      "       health_insurance  opinion_h1n1_vacc_effective  opinion_h1n1_risk  \\\n",
      "count      11558.000000                 21039.000000       21049.000000   \n",
      "mean           0.880689                     3.852512           2.338828   \n",
      "std            0.324168                     1.002453           1.286229   \n",
      "min            0.000000                     1.000000           1.000000   \n",
      "25%            1.000000                     3.000000           1.000000   \n",
      "50%            1.000000                     4.000000           2.000000   \n",
      "75%            1.000000                     5.000000           4.000000   \n",
      "max            1.000000                     5.000000           5.000000   \n",
      "\n",
      "       opinion_h1n1_sick_from_vacc  opinion_seas_vacc_effective  \\\n",
      "count                 21042.000000                 20993.000000   \n",
      "mean                      2.352058                     4.025104   \n",
      "std                       1.363952                     1.083890   \n",
      "min                       1.000000                     1.000000   \n",
      "25%                       1.000000                     4.000000   \n",
      "50%                       2.000000                     4.000000   \n",
      "75%                       4.000000                     5.000000   \n",
      "max                       5.000000                     5.000000   \n",
      "\n",
      "       opinion_seas_risk  opinion_seas_sick_from_vacc  household_adults  \\\n",
      "count       20947.000000                 20933.000000      21162.000000   \n",
      "mean            2.714518                     2.113887          0.882856   \n",
      "std             1.384856                     1.331147          0.754070   \n",
      "min             1.000000                     1.000000          0.000000   \n",
      "25%             2.000000                     1.000000          0.000000   \n",
      "50%             2.000000                     2.000000          1.000000   \n",
      "75%             4.000000                     4.000000          1.000000   \n",
      "max             5.000000                     5.000000          3.000000   \n",
      "\n",
      "       household_children  \n",
      "count        21162.000000  \n",
      "mean             0.537189  \n",
      "std              0.929824  \n",
      "min              0.000000  \n",
      "25%              0.000000  \n",
      "50%              0.000000  \n",
      "75%              1.000000  \n",
      "max              3.000000  \n",
      "\n",
      "[8 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento\n",
    "\n",
    "Para la parte de Preprocesamiento vamos a utilizar pipelines, que contengan todo el preprocesamiento. Un pipeline es una herramienta de procesamiento de datos que organiza, automatiza y encadena múltiples pasos del preprocesamiento y modelado en un flujo continuo. Se utiliza comúnmente en proyectos de machine learning para garantizar consistencia, evitar fugas de datos y mejorar la reproducibilidad.\n",
    "\n",
    "Componentes clave de un pipeline:\n",
    "\n",
    "    1. Transformadores:\n",
    "        Son los pasos de preprocesamiento, como:\n",
    "\n",
    "            - Imputación de valores faltantes.\n",
    "            - Escalado o normalización de datos.\n",
    "            - Codificación de variables categóricas.\n",
    "            - Selección o reducción de características.\n",
    "\n",
    "    2. Modelo de predicción:\n",
    "        Es el paso final del pipeline. Puede ser un clasificador o un regresor.\n",
    "\n",
    "    3. Encadenamiento:\n",
    "        Todos los pasos del pipeline están conectados. Los datos fluyen secuencialmente desde el primer paso hasta el último.\n",
    "\n",
    "### Valores faltantes \n",
    "\n",
    "Vamos a ver si existen valores faltantes en el dataset y a decidir cómo tratarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h1n1_concern                      73\n",
      "h1n1_knowledge                    90\n",
      "behavioral_antiviral_meds         57\n",
      "behavioral_avoidance             168\n",
      "behavioral_face_mask              14\n",
      "behavioral_wash_hands             32\n",
      "behavioral_large_gatherings       71\n",
      "behavioral_outside_home           65\n",
      "behavioral_touch_face             96\n",
      "doctor_recc_h1n1                1718\n",
      "doctor_recc_seasonal            1718\n",
      "chronic_med_condition            768\n",
      "child_under_6_months             666\n",
      "health_worker                    649\n",
      "health_insurance                9807\n",
      "opinion_h1n1_vacc_effective      326\n",
      "opinion_h1n1_risk                316\n",
      "opinion_h1n1_sick_from_vacc      323\n",
      "opinion_seas_vacc_effective      372\n",
      "opinion_seas_risk                418\n",
      "opinion_seas_sick_from_vacc      432\n",
      "age_group                          0\n",
      "education                       1127\n",
      "race                               0\n",
      "sex                                0\n",
      "income_poverty                  3530\n",
      "marital_status                  1122\n",
      "rent_or_own                     1619\n",
      "employment_status               1172\n",
      "hhs_geo_region                     0\n",
      "census_msa                         0\n",
      "household_adults                 203\n",
      "household_children               203\n",
      "employment_industry            10607\n",
      "employment_occupation          10716\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos cómo la mayoría de variables tienen valores faltantes y, además, no contienen precisamente pocos por lo que la decisión no podrá ser eliminar los registros con valores faltantes, sino que habrá que aplicar otras técnicas. \n",
    "\n",
    "Algunas variables faltantes pueden ser completadas basándose en información presente en otras columnas, por ejemplo:\n",
    "Si employment_status es \"Unemployed\" o \"Not in Labor Force\", las variables employment_industry y employment_occupation deberían ser asignadas como \"Not Applicable\" (o un valor similar).\n",
    "\n",
    "Para variables categóricas que no tienen una relación lógica clara con otras columnas vamos a utilizar la moda porque mantiene la consistencia con las categorías existentes y es útil para variables donde los valores no tienen un rango amplio o continuo.\n",
    "\n",
    "Para variables numéricas continuas o discretas, elegimos la imputación con la mediana ya que es más robusta que la media si hay valores extremos. Además, el escalado puede ser útil dependiendo del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset preprocesado guardado como 'preprocessed_training_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Variables ordinales (numéricas y de texto)\n",
    "# Estas variables tienen un orden implícito (por ejemplo, nivel de preocupación o educación).\n",
    "# Se imputan por moda (el valor más frecuente).\n",
    "ordinal_cols = ['h1n1_concern', 'h1n1_knowledge', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk', \n",
    "                'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_risk', 'opinion_seas_sick_from_vacc']\n",
    "ordinal_cols_str = ['age_group', 'education', 'income_poverty']\n",
    "\n",
    "# Variables binarias (numéricas y de texto)\n",
    "# Estas variables son de tipo binario (sí/no) o representadas como texto (por ejemplo, \"Male\" o \"Female\").\n",
    "# También se imputan por moda.\n",
    "binary_cols = ['behavioral_antiviral_meds', 'behavioral_avoidance', 'behavioral_face_mask', 'behavioral_wash_hands',\n",
    "               'behavioral_large_gatherings', 'behavioral_outside_home', 'behavioral_touch_face', 'doctor_recc_h1n1',\n",
    "               'doctor_recc_seasonal', 'chronic_med_condition', 'child_under_6_months', 'health_worker']\n",
    "binary_cols_str = ['sex', 'marital_status', 'rent_or_own']\n",
    "\n",
    "# Variables categóricas nominales (sin orden)\n",
    "# Estas variables no tienen un orden implícito (por ejemplo, regiones geográficas o estados laborales).\n",
    "# Se codificarán utilizando OneHotEncoder.\n",
    "nominal_cols_str = ['race', 'employment_status', 'hhs_geo_region', 'census_msa', 'employment_industry', 'employment_occupation']\n",
    "\n",
    "# Variables numéricas\n",
    "# Estas son variables cuantitativas (por ejemplo, número de adultos o niños en el hogar).\n",
    "numeric_cols = ['household_adults', 'household_children']\n",
    "\n",
    "# Función personalizada para manejar valores faltantes específicos\n",
    "# Si el estado laboral es \"Not in Labor Force\" o \"Unemployed\", marcamos las columnas\n",
    "# `employment_industry` y `employment_occupation` con el valor \"Missing\".\n",
    "def mark_missing(df):\n",
    "    df[['employment_industry', 'employment_occupation']] = df[['employment_industry', 'employment_occupation']].mask(\n",
    "        df['employment_status'].isin(['Not in Labor Force', 'Unemployed']), 'Missing'\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Mapeos de orden para columnas ordinales en formato de texto\n",
    "# Esto define el orden explícito de las categorías para columnas como \"age_group\" y \"education\".\n",
    "ordinal_col_order = {\n",
    "    'age_group': ['18 - 34 Years', '35 - 44 Years', '55 - 64 Years', '45 - 54 Years', '65+ Years'],\n",
    "    'education': ['< 12 Years', '12 Years', 'Some College', 'College Graduate'],\n",
    "    'income_poverty': ['Below Poverty', '<= $75,000, Above Poverty', '> $75,000']\n",
    "}\n",
    "\n",
    "# Pipeline para columnas ordinales numéricas\n",
    "# Imputa valores faltantes usando la moda.\n",
    "ordinal_numeric_pipeline = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Pipeline para columnas ordinales en formato de texto\n",
    "# Imputa valores faltantes usando la moda y luego codifica las categorías en números según el orden definido.\n",
    "ordinal_str_pipeline = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(categories=[ordinal_col_order[col] for col in ordinal_cols_str]))\n",
    "])\n",
    "\n",
    "# Pipeline para columnas binarias numéricas\n",
    "# Imputa valores faltantes usando la moda.\n",
    "binary_pipeline = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# Pipeline para columnas binarias en formato de texto\n",
    "# Imputa valores faltantes usando la moda y las codifica como números (0 y 1).\n",
    "binary_str_pipeline = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ordinal_encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "# Pipeline para columnas categóricas nominales\n",
    "# Imputa valores faltantes usando la moda y luego las codifica utilizando OneHotEncoder.\n",
    "nominal_pipeline = Pipeline([\n",
    "    ('simple_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Preprocesamiento general con ColumnTransformer\n",
    "# Combina los pipelines definidos para cada tipo de columna.\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ordinal_numeric', ordinal_numeric_pipeline, ordinal_cols + numeric_cols),\n",
    "        ('ordinal_str', ordinal_str_pipeline, ordinal_cols_str),\n",
    "        ('binary', binary_pipeline, binary_cols),\n",
    "        ('binary_str', binary_str_pipeline, binary_cols_str),\n",
    "        ('nominal', nominal_pipeline, nominal_cols_str)\n",
    "    ],\n",
    "    remainder='drop'  # Eliminamos columnas no especificadas en los transformadores\n",
    ")\n",
    "\n",
    "# Pipeline general\n",
    "# Incluye un paso inicial para manejar casos específicos (mark_missing) y luego aplica el ColumnTransformer.\n",
    "data_preprocessing_pipeline = Pipeline([\n",
    "    ('handle_missing_employment', FunctionTransformer(mark_missing, validate=False)),\n",
    "    ('preprocessor', column_transformer)\n",
    "])\n",
    "\n",
    "# Aplicar el pipeline al dataset\n",
    "# Aplica el pipeline para imputar valores faltantes y realizar las transformaciones.\n",
    "preprocessed_data = data_preprocessing_pipeline.fit_transform(df)\n",
    "\n",
    "# Generar los nombres de las columnas para el DataFrame final\n",
    "# Se incluyen los nombres generados por OneHotEncoder para las columnas nominales.\n",
    "output_columns = (\n",
    "    ordinal_cols + numeric_cols +\n",
    "    ordinal_cols_str +\n",
    "    binary_cols + binary_cols_str +\n",
    "    list(data_preprocessing_pipeline.named_steps['preprocessor'].transformers_[4][1].named_steps['one_hot_encoder'].get_feature_names_out(nominal_cols_str)) # Columnas nominales codificadas\n",
    ")\n",
    "\n",
    "# Convertir los datos transformados en un DataFrame\n",
    "preprocessed_df = pd.DataFrame(preprocessed_data, columns=output_columns)\n",
    "\n",
    "# Crear un índice secuencial para 'respondent_id' que se ha perdido en el proceso y añadirla al DataFrame\n",
    "respondent_id = pd.Series(range(1, preprocessed_data.shape[0] + 1), name='respondent_id')\n",
    "preprocessed_df.insert(0, 'respondent_id', respondent_id)\n",
    "\n",
    "# Guardar el resultado en un archivo CSV\n",
    "preprocessed_df.to_csv('../Data/Prueba_Ruxi/preprocessed_training_dataset.csv', index=False)\n",
    "print(\"Dataset preprocesado guardado como 'preprocessed_training_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21365, 95)\n",
      "respondent_id                     0\n",
      "h1n1_concern                      0\n",
      "h1n1_knowledge                    0\n",
      "opinion_h1n1_vacc_effective       0\n",
      "opinion_h1n1_risk                 0\n",
      "                                 ..\n",
      "employment_occupation_vlluhbov    0\n",
      "employment_occupation_xgwztkwe    0\n",
      "employment_occupation_xqwwgdyp    0\n",
      "employment_occupation_xtkaffoo    0\n",
      "employment_occupation_xzmlyyjv    0\n",
      "Length: 95, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_df.shape)\n",
    "print(preprocessed_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de prueba preprocesado guardado como 'preprocessed_test_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el mismo preprocesamiento al dataset de prueba\n",
    "test_set_preprocessed = data_preprocessing_pipeline.transform(X_test)\n",
    "\n",
    "# Generar los nombres de columnas para el DataFrame de prueba\n",
    "output_columns = (\n",
    "    ordinal_cols + numeric_cols +\n",
    "    ordinal_cols_str +\n",
    "    binary_cols + binary_cols_str +\n",
    "    list(data_preprocessing_pipeline.named_steps['preprocessor'].transformers_[4][1].named_steps['one_hot_encoder'].get_feature_names_out(nominal_cols_str))\n",
    ")\n",
    "\n",
    "# Convertir los datos transformados a un DataFrame\n",
    "test_set_preprocessed_df = pd.DataFrame(test_set_preprocessed, columns=output_columns, index=X_test.index)\n",
    "\n",
    "# Añadir respondent_id como columna (ya está en el índice del DataFrame)\n",
    "test_set_preprocessed_df.reset_index(inplace=True)\n",
    "\n",
    "# Guardar el DataFrame preprocesado en un archivo CSV\n",
    "test_set_preprocessed_df.to_csv(\"../Data/Prueba_Ruxi/preprocessed_test_dataset.csv\", index=False)\n",
    "print(\"Dataset de prueba preprocesado guardado como 'preprocessed_test_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de prueba preprocesado guardado como 'preprocessed_submission_datasetset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Aplicar el mismo preprocesamiento al dataset de prueba\n",
    "test_set_preprocessed = data_preprocessing_pipeline.transform(test_set_features_submission)\n",
    "\n",
    "# Generar los nombres de columnas para el DataFrame de prueba\n",
    "output_columns = (\n",
    "    ordinal_cols + numeric_cols +\n",
    "    ordinal_cols_str +\n",
    "    binary_cols + binary_cols_str +\n",
    "    list(data_preprocessing_pipeline.named_steps['preprocessor'].transformers_[4][1].named_steps['one_hot_encoder'].get_feature_names_out(nominal_cols_str))\n",
    ")\n",
    "\n",
    "# Convertir los datos transformados a un DataFrame\n",
    "test_set_preprocessed_df = pd.DataFrame(test_set_preprocessed, columns=output_columns, index=test_set_features_submission.index)\n",
    "\n",
    "# Añadir respondent_id como columna (ya está en el índice del DataFrame)\n",
    "test_set_preprocessed_df.reset_index(inplace=True)\n",
    "\n",
    "# Guardar el DataFrame preprocesado en un archivo CSV\n",
    "test_set_preprocessed_df.to_csv(\"../Data/Prueba_Ruxi/preprocessed_submission_dataset.csv\", index=False)\n",
    "print(\"Dataset de prueba preprocesado guardado como 'preprocessed_submission_datasetset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset de prueba con etiquetas guardado como 'labels_train_dataset.csv'\n",
      "Dataset de prueba con etiquetas guardado como 'labels_test_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "y_train.to_csv(\"../Data/Prueba_Ruxi/labels_train_dataset.csv\")\n",
    "print(\"Dataset de prueba con etiquetas guardado como 'labels_train_dataset.csv'\")\n",
    "\n",
    "y_test.to_csv(\"../Data/Prueba_Ruxi/labels_test_dataset.csv\")\n",
    "print(\"Dataset de prueba con etiquetas guardado como 'labels_test_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
