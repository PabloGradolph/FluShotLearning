{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20069938",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "import graphviz\n",
    "import joblib\n",
    "import optuna\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "493ac5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"../Data/Prueba_Ruxi/preprocessed_training_dataset.csv\", index_col=\"respondent_id\")\n",
    "X_test = pd.read_csv(\"../Data/Prueba_Ruxi/preprocessed_test_dataset.csv\", index_col=\"respondent_id\")\n",
    "y_train = pd.read_csv(\"../Data/Prueba_Ruxi/labels_train_dataset.csv\", index_col=\"respondent_id\")\n",
    "y_test =  pd.read_csv(\"../Data/Prueba_Ruxi/labels_test_dataset.csv\", index_col=\"respondent_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ee550b",
   "metadata": {},
   "source": [
    "# AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119cf1dc",
   "metadata": {},
   "source": [
    "Si no se especifica el parámetro base_estimator, se utiliza DecisionTreeClassifier por defecto. En el caso de AdaBoost, es interesante tener clasificadores débiles que produzcan ajustes diversos a los datos. Se prueben otros clasificadores débiles, como LogisticRegression o 1NN (por ejemplo).\n",
    "\n",
    "El learning rate controla cómo “sobreajustamos” a los datos que resultaron incorrectos en la iteración previa. Pruebe a jugar incrementando el learning rate con learning_rate frente al número de iteraciones n_estimators, intentando reducir al máximo el segundo argumento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f11a847",
   "metadata": {},
   "source": [
    "# Árbol de clasificación "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a557db",
   "metadata": {},
   "source": [
    "# Optimización con Bayes Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f7e23191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: OrderedDict([('estimator__algorithm', 'SAMME'), ('estimator__estimator__max_depth', 7), ('estimator__estimator__min_samples_leaf', 1), ('estimator__estimator__min_samples_split', 2), ('estimator__learning_rate', 0.06982974562429808), ('estimator__n_estimators', 162)])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Crear el modelo base con class_weight='balanced'\n",
    "ada_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(class_weight='balanced'),  \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Envolverlo en MultiOutputClassifier para predicción multietiqueta\n",
    "multi_ada = MultiOutputClassifier(ada_model)\n",
    "\n",
    "# Espacio de búsqueda de hiperparámetros\n",
    "search_space = {\n",
    "    'estimator__n_estimators': Integer(50, 300),  \n",
    "    'estimator__learning_rate': Real(0.01, 1.0, prior='log-uniform'), \n",
    "    'estimator__estimator__max_depth': Integer(1, 10), \n",
    "    'estimator__estimator__min_samples_split': Integer(2, 20), \n",
    "    'estimator__estimator__min_samples_leaf': Integer(1, 10), \n",
    "    'estimator__algorithm': ['SAMME'], \n",
    "}\n",
    "\n",
    "# Configurar BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    multi_ada,\n",
    "    search_space,\n",
    "    cv=5,\n",
    "    n_iter=100,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros:\", opt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5faf608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'AdaBoost_arbol_bayes.pkl'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>param_estimator__n_estimators</th>\n",
       "      <th>param_estimator__learning_rate</th>\n",
       "      <th>param_estimator__estimator__max_depth</th>\n",
       "      <th>param_estimator__estimator__min_samples_split</th>\n",
       "      <th>param_estimator__estimator__min_samples_leaf</th>\n",
       "      <th>param_estimator__algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.841315</td>\n",
       "      <td>162</td>\n",
       "      <td>0.069830</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>SAMME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.841189</td>\n",
       "      <td>300</td>\n",
       "      <td>0.061375</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>SAMME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.841177</td>\n",
       "      <td>274</td>\n",
       "      <td>0.072081</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>SAMME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.841163</td>\n",
       "      <td>241</td>\n",
       "      <td>0.049956</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>SAMME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.841133</td>\n",
       "      <td>300</td>\n",
       "      <td>0.072636</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "      <td>SAMME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  param_estimator__n_estimators  \\\n",
       "99         0.841315                            162   \n",
       "51         0.841189                            300   \n",
       "67         0.841177                            274   \n",
       "58         0.841163                            241   \n",
       "52         0.841133                            300   \n",
       "\n",
       "    param_estimator__learning_rate  param_estimator__estimator__max_depth  \\\n",
       "99                        0.069830                                      7   \n",
       "51                        0.061375                                      7   \n",
       "67                        0.072081                                      7   \n",
       "58                        0.049956                                      7   \n",
       "52                        0.072636                                      7   \n",
       "\n",
       "    param_estimator__estimator__min_samples_split  \\\n",
       "99                                              2   \n",
       "51                                             20   \n",
       "67                                             20   \n",
       "58                                             20   \n",
       "52                                             20   \n",
       "\n",
       "    param_estimator__estimator__min_samples_leaf param_estimator__algorithm  \n",
       "99                                             1                      SAMME  \n",
       "51                                            10                      SAMME  \n",
       "67                                             1                      SAMME  \n",
       "58                                            10                      SAMME  \n",
       "52                                            10                      SAMME  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Guardar el mejor modelo optimizado\n",
    "joblib.dump(opt.best_estimator_, \"../Modelos/Prueba_Ruxi/AdaBoost_arbol_bayes.pkl\")\n",
    "print(\"Modelo guardado como 'AdaBoost_arbol_bayes.pkl'\")\n",
    "\n",
    "# Guardar resultados\n",
    "results = pd.DataFrame(opt.cv_results_)\n",
    "columns = [\n",
    "    'mean_test_score',  \n",
    "    'param_estimator__n_estimators',  \n",
    "    'param_estimator__learning_rate', \n",
    "    'param_estimator__estimator__max_depth',\n",
    "    'param_estimator__estimator__min_samples_split',\n",
    "    'param_estimator__estimator__min_samples_leaf',\n",
    "    'param_estimator__algorithm',  \n",
    "]\n",
    "results_table = results[columns].copy()\n",
    "results_table.to_csv('../Results/Prueba_Ruxi/AdaBoost_arbol_bayes_results_table.csv', index=False)\n",
    "results_table.sort_values(by=['mean_test_score'], ascending=False).head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d868060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas de evaluación-----------------------------------------------\n",
      "ROC AUC Scores del mejor modelo: [0.8559092720649415, 0.8868424175543236]\n",
      "Accuracy Scores del mejor modelo: [0.8000468055230517, 0.8026211092908964] \n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.75      0.61      4539\n",
      "           1       0.78      0.80      0.79      9947\n",
      "\n",
      "   micro avg       0.68      0.78      0.73     14486\n",
      "   macro avg       0.65      0.77      0.70     14486\n",
      "weighted avg       0.70      0.78      0.73     14486\n",
      " samples avg       0.37      0.39      0.37     14486\n",
      "\n",
      "Probabilidades-----------------------------------------------------\n",
      "Primeras 5 probabilities para label 0: [0.72667418 0.79763732 0.11920292 0.11920292 0.13474615]\n",
      "Primeras 5 probabilities para label 1: [0.75551147 0.7739071  0.73269013 0.16065331 0.46835083]\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion en train\n",
    "best_model = joblib.load(\"../Modelos/Prueba_Ruxi/AdaBoost_arbol_bayes.pkl\")\n",
    "y_pred_proba = best_model.predict_proba(X_train)\n",
    "y_pred = best_model.predict(X_train)\n",
    "\n",
    "# Calcular ROC AUC para cada label\n",
    "roc_auc_scores = [\n",
    "    roc_auc_score(y_train.iloc[:, i], y_pred_proba[i][:, 1]) for i in range(y_train.shape[1])\n",
    "]\n",
    "\n",
    "# Calcular Accuracy para cada label\n",
    "accuracy_scores = [\n",
    "    accuracy_score(y_train.iloc[:, i], y_pred_proba[i].argmax(axis=1)) for i in range(y_train.shape[1])\n",
    "]\n",
    "\n",
    "print(\"Medidas de evaluación-----------------------------------------------\")\n",
    "print(\"ROC AUC Scores del mejor modelo:\", roc_auc_scores)\n",
    "print(\"Accuracy Scores del mejor modelo:\", accuracy_scores, \"\\n\")\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_train, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Probabilidades-----------------------------------------------------\")\n",
    "print(\"Primeras 5 probabilities para label 0:\", y_pred_proba[0][:5, 1])\n",
    "print(\"Primeras 5 probabilities para label 1:\", y_pred_proba[1][:5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564f2c97",
   "metadata": {},
   "source": [
    "# Optimización con Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c08356c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-23 12:06:17,969] A new study created in memory with name: no-name-926d8e57-8a21-4a64-9f3b-91c140324ba6\n",
      "[I 2025-01-23 12:06:43,583] Trial 0 finished with value: 0.8274721993415619 and parameters: {'max_depth': 3, 'n_estimators': 193, 'learning_rate': 0.1653638212177839, 'min_samples_split': 12, 'min_samples_leaf': 7, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.8274721993415619.\n",
      "[I 2025-01-23 12:07:23,758] Trial 1 finished with value: 0.8196249132970154 and parameters: {'max_depth': 2, 'n_estimators': 275, 'learning_rate': 0.04838639067165953, 'min_samples_split': 9, 'min_samples_leaf': 2, 'algorithm': 'SAMME'}. Best is trial 0 with value: 0.8274721993415619.\n",
      "[I 2025-01-23 12:08:21,360] Trial 2 finished with value: 0.8286982366072035 and parameters: {'max_depth': 4, 'n_estimators': 138, 'learning_rate': 0.01856062250549623, 'min_samples_split': 19, 'min_samples_leaf': 7, 'algorithm': 'SAMME'}. Best is trial 2 with value: 0.8286982366072035.\n",
      "[I 2025-01-23 12:08:48,433] Trial 3 finished with value: 0.8327639962849689 and parameters: {'max_depth': 4, 'n_estimators': 83, 'learning_rate': 0.07478906638976432, 'min_samples_split': 15, 'min_samples_leaf': 1, 'algorithm': 'SAMME'}. Best is trial 3 with value: 0.8327639962849689.\n",
      "[I 2025-01-23 12:09:17,715] Trial 4 finished with value: 0.8113160919639608 and parameters: {'max_depth': 1, 'n_estimators': 239, 'learning_rate': 0.27696612313096597, 'min_samples_split': 5, 'min_samples_leaf': 8, 'algorithm': 'SAMME'}. Best is trial 3 with value: 0.8327639962849689.\n",
      "[I 2025-01-23 12:10:08,355] Trial 5 finished with value: 0.8400371786209533 and parameters: {'max_depth': 7, 'n_estimators': 141, 'learning_rate': 0.1521491905724189, 'min_samples_split': 11, 'min_samples_leaf': 8, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.8400371786209533.\n",
      "[I 2025-01-23 12:11:01,694] Trial 6 finished with value: 0.8282742175638871 and parameters: {'max_depth': 3, 'n_estimators': 201, 'learning_rate': 0.02941818048966019, 'min_samples_split': 11, 'min_samples_leaf': 5, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.8400371786209533.\n",
      "[I 2025-01-23 12:11:06,727] Trial 7 finished with value: 0.8235612253004184 and parameters: {'max_depth': 4, 'n_estimators': 160, 'learning_rate': 0.821279124843928, 'min_samples_split': 19, 'min_samples_leaf': 7, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.8400371786209533.\n",
      "[I 2025-01-23 12:13:56,105] Trial 8 finished with value: 0.8390420911720546 and parameters: {'max_depth': 7, 'n_estimators': 268, 'learning_rate': 0.013072479696226848, 'min_samples_split': 15, 'min_samples_leaf': 6, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.8400371786209533.\n",
      "[I 2025-01-23 12:14:08,828] Trial 9 finished with value: 0.8121315857322127 and parameters: {'max_depth': 1, 'n_estimators': 165, 'learning_rate': 0.30920163142941404, 'min_samples_split': 17, 'min_samples_leaf': 6, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.8400371786209533.\n",
      "[I 2025-01-23 12:14:46,899] Trial 10 finished with value: 0.805612471885462 and parameters: {'max_depth': 10, 'n_estimators': 54, 'learning_rate': 0.8684359363654816, 'min_samples_split': 2, 'min_samples_leaf': 10, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.8400371786209533.\n",
      "[I 2025-01-23 12:16:46,639] Trial 11 finished with value: 0.8343032451292662 and parameters: {'max_depth': 8, 'n_estimators': 118, 'learning_rate': 0.011526847207173313, 'min_samples_split': 13, 'min_samples_leaf': 4, 'algorithm': 'SAMME'}. Best is trial 5 with value: 0.8400371786209533.\n",
      "[I 2025-01-23 12:18:43,742] Trial 12 finished with value: 0.8402297044547696 and parameters: {'max_depth': 8, 'n_estimators': 295, 'learning_rate': 0.08300395672988684, 'min_samples_split': 8, 'min_samples_leaf': 10, 'algorithm': 'SAMME'}. Best is trial 12 with value: 0.8402297044547696.\n",
      "[I 2025-01-23 12:19:23,234] Trial 13 finished with value: 0.840303944534172 and parameters: {'max_depth': 7, 'n_estimators': 227, 'learning_rate': 0.12621186329750728, 'min_samples_split': 8, 'min_samples_leaf': 10, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.840303944534172.\n",
      "[I 2025-01-23 12:21:14,548] Trial 14 finished with value: 0.839222151905344 and parameters: {'max_depth': 9, 'n_estimators': 293, 'learning_rate': 0.07701473194708301, 'min_samples_split': 7, 'min_samples_leaf': 10, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.840303944534172.\n",
      "[I 2025-01-23 12:22:39,647] Trial 15 finished with value: 0.839549986425622 and parameters: {'max_depth': 6, 'n_estimators': 226, 'learning_rate': 0.0431987430391079, 'min_samples_split': 5, 'min_samples_leaf': 9, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.840303944534172.\n",
      "[I 2025-01-23 12:22:52,482] Trial 16 finished with value: 0.835723809993867 and parameters: {'max_depth': 6, 'n_estimators': 236, 'learning_rate': 0.34339718507009204, 'min_samples_split': 8, 'min_samples_leaf': 10, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.840303944534172.\n",
      "[I 2025-01-23 12:23:54,575] Trial 17 finished with value: 0.8379439702200161 and parameters: {'max_depth': 9, 'n_estimators': 298, 'learning_rate': 0.1420880079311687, 'min_samples_split': 5, 'min_samples_leaf': 9, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.840303944534172.\n",
      "[I 2025-01-23 12:24:54,391] Trial 18 finished with value: 0.8398556990883153 and parameters: {'max_depth': 8, 'n_estimators': 258, 'learning_rate': 0.09824908693169118, 'min_samples_split': 2, 'min_samples_leaf': 4, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.840303944534172.\n",
      "[I 2025-01-23 12:26:17,361] Trial 19 finished with value: 0.822587500911277 and parameters: {'max_depth': 10, 'n_estimators': 209, 'learning_rate': 0.4737295988081107, 'min_samples_split': 9, 'min_samples_leaf': 9, 'algorithm': 'SAMME'}. Best is trial 13 with value: 0.840303944534172.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "def objective(trial):\n",
    "    # Definir el espacio de búsqueda de hiperparámetros\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 10)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.01, 1.0, log=True)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    algorithm = trial.suggest_categorical('algorithm', ['SAMME'])\n",
    "\n",
    "    # Crear el modelo base con DecisionTreeClassifier\n",
    "    base_estimator = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        class_weight='balanced',\n",
    "    )\n",
    "\n",
    "    # Crear el modelo de AdaBoostClassifier\n",
    "    ada_model = AdaBoostClassifier(\n",
    "        estimator=base_estimator,\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        algorithm=algorithm,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Envolver el modelo en MultiOutputClassifier para predicción multietiqueta\n",
    "    multi_ada = MultiOutputClassifier(ada_model)\n",
    "\n",
    "    # Realizar la validación cruzada para calcular el ROC AUC\n",
    "    roc_auc_scores = cross_val_score(\n",
    "        multi_ada, X_train, y_train, cv=5, scoring='roc_auc'\n",
    "    )\n",
    "\n",
    "    # Promediar los ROC AUC obtenidos durante la validación cruzada\n",
    "    score = roc_auc_scores.mean()\n",
    "\n",
    "    return score\n",
    "\n",
    "# Crear un estudio de optimización con Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=20)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3a1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor modelo guardado como 'AdaBoost_arbol_optuna.pkl'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrenar el mejor modelo con los parámetros encontrados\n",
    "best_params = study.best_params\n",
    "best_model = AdaBoostClassifier(\n",
    "    estimator=DecisionTreeClassifier(\n",
    "        max_depth=best_params['max_depth'],\n",
    "        min_samples_split=best_params['min_samples_split'],\n",
    "        min_samples_leaf=best_params['min_samples_leaf']\n",
    "    ),\n",
    "    n_estimators=best_params['n_estimators'],\n",
    "    learning_rate=best_params['learning_rate'],\n",
    "    algorithm=best_params['algorithm'],\n",
    "    random_state=42\n",
    ")\n",
    "multi_best_model = MultiOutputClassifier(best_model)\n",
    "\n",
    "# Ajustar el mejor modelo con los datos de entrenamiento\n",
    "multi_best_model.fit(X_train, y_train)\n",
    "\n",
    "# Guardar el mejor modelo\n",
    "joblib.dump(multi_best_model, \"../Modelos/Prueba_Ruxi/AdaBoost_arbol_optuna.pkl\")\n",
    "print(\"Mejor modelo guardado como 'AdaBoost_arbol_optuna.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "144fc106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados: {'max_depth': 7, 'n_estimators': 227, 'learning_rate': 0.12621186329750728, 'min_samples_split': 8, 'min_samples_leaf': 10, 'algorithm': 'SAMME'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params_learning_rate</th>\n",
       "      <th>params_max_depth</th>\n",
       "      <th>params_min_samples_leaf</th>\n",
       "      <th>params_min_samples_split</th>\n",
       "      <th>params_n_estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.840304</td>\n",
       "      <td>0.126212</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.840230</td>\n",
       "      <td>0.083004</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.840037</td>\n",
       "      <td>0.152149</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.839856</td>\n",
       "      <td>0.098249</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.839550</td>\n",
       "      <td>0.043199</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value  params_learning_rate  params_max_depth  params_min_samples_leaf  \\\n",
       "13  0.840304              0.126212                 7                       10   \n",
       "12  0.840230              0.083004                 8                       10   \n",
       "5   0.840037              0.152149                 7                        8   \n",
       "18  0.839856              0.098249                 8                        4   \n",
       "15  0.839550              0.043199                 6                        9   \n",
       "\n",
       "    params_min_samples_split  params_n_estimators  \n",
       "13                         8                  227  \n",
       "12                         8                  295  \n",
       "5                         11                  141  \n",
       "18                         2                  258  \n",
       "15                         5                  226  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mejores parámetros encontrados:\", study.best_params)\n",
    "\n",
    "# Guardar resultados\n",
    "trials_df = study.trials_dataframe()\n",
    "\n",
    "columns = [\n",
    "    'value',  \n",
    "    'params_learning_rate',  \n",
    "    'params_n_estimators', \n",
    "    'params_max_depth',\n",
    "    'params_min_samples_leaf',\n",
    "    'params_min_samples_split',\n",
    "    'params_max_depth', \n",
    "    'params.algorithm'  \n",
    "]\n",
    "\n",
    "trials_df = trials_df[trials_df.columns.intersection(columns)]\n",
    "trials_df.sort_values(by='value', ascending=False, inplace=True)\n",
    "\n",
    "results_csv_path = '../Results/Prueba_Ruxi/AdaBoost_arbol_optuna_results_table.csv'\n",
    "trials_df.to_csv(results_csv_path, index=False)\n",
    "trials_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219a396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas de evaluación-----------------------------------------------\n",
      "ROC AUC Scores del mejor modelo: [0.8851280829951715, 0.8920962041190001]\n",
      "Accuracy Scores del mejor modelo: [0.861362040720805, 0.8085654107184648] \n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.51      0.61      4539\n",
      "           1       0.80      0.78      0.79      9947\n",
      "\n",
      "   micro avg       0.79      0.70      0.74     14486\n",
      "   macro avg       0.78      0.65      0.70     14486\n",
      "weighted avg       0.79      0.70      0.73     14486\n",
      " samples avg       0.37      0.35      0.35     14486\n",
      "\n",
      "Probabilidades-----------------------------------------------------\n",
      "Primeras 5 probabilities para label 0: [0.42505038 0.39107267 0.13239643 0.21232802 0.24617575]\n",
      "Primeras 5 probabilities para label 1: [0.65670746 0.677444   0.65941646 0.25544606 0.43632201]\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion en train\n",
    "best_model = joblib.load(\"../Modelos/Prueba_Ruxi/AdaBoost_arbol_optuna.pkl\")\n",
    "y_pred_proba = best_model.predict_proba(X_train)\n",
    "y_pred = best_model.predict(X_train)\n",
    "\n",
    "# Calcular ROC AUC para cada label\n",
    "roc_auc_scores = [\n",
    "    roc_auc_score(y_train.iloc[:, i], y_pred_proba[i][:, 1]) for i in range(y_train.shape[1])\n",
    "]\n",
    "\n",
    "# Calcular Accuracy para cada label\n",
    "accuracy_scores = [\n",
    "    accuracy_score(y_train.iloc[:, i], y_pred_proba[i].argmax(axis=1)) for i in range(y_train.shape[1])\n",
    "]\n",
    "\n",
    "print(\"Medidas de evaluación-----------------------------------------------\")\n",
    "print(\"ROC AUC Scores del mejor modelo:\", roc_auc_scores)\n",
    "print(\"Accuracy Scores del mejor modelo:\", accuracy_scores, \"\\n\")\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_train, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Probabilidades-----------------------------------------------------\")\n",
    "print(\"Primeras 5 probabilities para label 0:\", y_pred_proba[0][:5, 1])\n",
    "print(\"Primeras 5 probabilities para label 1:\", y_pred_proba[1][:5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192686a9",
   "metadata": {},
   "source": [
    "# Evaluación en test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4c506012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medidas de evaluación-----------------------------------------------\n",
      "ROC AUC Scores del mejor modelo: [0.8388333268760164, 0.8559335687262418]\n",
      "Accuracy Scores del mejor modelo: [0.8399475851740921, 0.7834144515162861] \n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.47      0.56      1135\n",
      "           1       0.77      0.76      0.76      2488\n",
      "\n",
      "   micro avg       0.75      0.67      0.71      3623\n",
      "   macro avg       0.72      0.62      0.66      3623\n",
      "weighted avg       0.74      0.67      0.70      3623\n",
      " samples avg       0.35      0.34      0.34      3623\n",
      "\n",
      "Probabilidades-----------------------------------------------------\n",
      "Primeras 5 probabilities para label 0: [0.23851672 0.57967882 0.24948673 0.35552768 0.33252167]\n",
      "Primeras 5 probabilities para label 1: [0.48358444 0.5822577  0.27803864 0.3685768  0.41425405]\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion en test\n",
    "best_model = joblib.load(\"../Modelos/Prueba_Ruxi/AdaBoost_arbol_optuna.pkl\")\n",
    "y_pred_proba = best_model.predict_proba(X_test)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular ROC AUC para cada label\n",
    "roc_auc_scores = [\n",
    "    roc_auc_score(y_test.iloc[:, i], y_pred_proba[i][:, 1]) for i in range(y_test.shape[1])\n",
    "]\n",
    "\n",
    "# Calcular Accuracy para cada label\n",
    "accuracy_scores = [\n",
    "    accuracy_score(y_test.iloc[:, i], y_pred_proba[i].argmax(axis=1)) for i in range(y_test.shape[1])\n",
    "]\n",
    "\n",
    "print(\"Medidas de evaluación-----------------------------------------------\")\n",
    "print(\"ROC AUC Scores del mejor modelo:\", roc_auc_scores)\n",
    "print(\"Accuracy Scores del mejor modelo:\", accuracy_scores, \"\\n\")\n",
    "print(\"Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "print(\"Probabilidades-----------------------------------------------------\")\n",
    "print(\"Primeras 5 probabilities para label 0:\", y_pred_proba[0][:5, 1])\n",
    "print(\"Primeras 5 probabilities para label 1:\", y_pred_proba[1][:5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf07c0",
   "metadata": {},
   "source": [
    "# Submission test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04abaf6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'AdaBoost_optuna_SMME.R_submission.csv' generado correctamente.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset de prueba preprocesado\n",
    "test_set_preprocessed = pd.read_csv(\"../Data/Prueba_Ruxi/preprocessed_submission_dataset.csv\")\n",
    "\n",
    "# Asegurarse de que respondent_id esté disponible\n",
    "respondent_ids = test_set_preprocessed['respondent_id']\n",
    "\n",
    "# Eliminar respondent_id del conjunto de características\n",
    "X_test_final = test_set_preprocessed.drop(columns=['respondent_id'])\n",
    "\n",
    "# Realizar predicciones de probabilidad\n",
    "best_model = joblib.load(\"../Modelos/AdaBoost_optuna_best_model.pkl\")\n",
    "y_proba_test = best_model.predict_proba(X_test_final)\n",
    "\n",
    "# Extraer las probabilidades para la clase positiva (1)\n",
    "y_proba_h1n1_test = y_proba_test[0][:, 1]  # Probabilidades para H1N1\n",
    "y_proba_seasonal_test = y_proba_test[1][:, 1]  # Probabilidades para vacuna estacional\n",
    "\n",
    "# Crear el DataFrame de submission\n",
    "submission = pd.DataFrame({\n",
    "    \"respondent_id\": respondent_ids,\n",
    "    \"h1n1_vaccine\": y_proba_h1n1_test,\n",
    "    \"seasonal_vaccine\": y_proba_seasonal_test\n",
    "})\n",
    "\n",
    "# Guardar el archivo de submission\n",
    "submission.to_csv(\"../Results/AdaBoost_arbol_optuna_submission.csv\", index=False)\n",
    "print(\"Archivo 'AdaBoost_arbol_optuna_submission.csv' generado correctamente.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4d993",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
