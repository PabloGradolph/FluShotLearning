{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clasificación con SVM\n",
    "\n",
    "Como se ha mencionado en el preprocesamiento, en el problema que aquí se estudia, cada individuo puede pertenecer a una clase, las dos o ninguna, por lo que se está tratando de un problema multietiqueta. Para usar una máquina de soporte vectorial en clasificación es necesario codificar la salida para que las distintas variantes de SVM pueda realizar la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"preprocessed_training_dataset.csv\")\n",
    "y_train = pd.read_csv(\"training_set_labels.csv\", index_col=\"respondent_id\")\n",
    "\n",
    "# Cargar el dataset de prueba\n",
    "X_test = pd.read_csv(\"preprocessed_test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (26707, 48) (26707, 2)\n",
      "Test set: (26708, 48)\n"
     ]
    }
   ],
   "source": [
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>hhs_geo_region_lrircsnp</th>\n",
       "      <th>hhs_geo_region_lzgpxyit</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>hhs_geo_region_oxchjgsf</th>\n",
       "      <th>hhs_geo_region_qufhixun</th>\n",
       "      <th>census_msa_MSA, Not Principle  City</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   h1n1_concern  h1n1_knowledge  opinion_h1n1_vacc_effective  \\\n",
       "0           2.0             2.0                          5.0   \n",
       "1           1.0             1.0                          4.0   \n",
       "2           2.0             2.0                          5.0   \n",
       "3           1.0             1.0                          4.0   \n",
       "4           3.0             1.0                          5.0   \n",
       "\n",
       "   opinion_h1n1_risk  opinion_h1n1_sick_from_vacc  \\\n",
       "0                1.0                          1.0   \n",
       "1                1.0                          1.0   \n",
       "2                4.0                          2.0   \n",
       "3                2.0                          2.0   \n",
       "4                2.0                          4.0   \n",
       "\n",
       "   opinion_seas_vacc_effective  opinion_seas_risk  \\\n",
       "0                          5.0                1.0   \n",
       "1                          4.0                1.0   \n",
       "2                          5.0                4.0   \n",
       "3                          4.0                4.0   \n",
       "4                          4.0                4.0   \n",
       "\n",
       "   opinion_seas_sick_from_vacc  age_group  education  ...  \\\n",
       "0                          1.0        1.0        3.0  ...   \n",
       "1                          1.0        0.0        1.0  ...   \n",
       "2                          4.0        2.0        3.0  ...   \n",
       "3                          2.0        4.0        1.0  ...   \n",
       "4                          2.0        1.0        1.0  ...   \n",
       "\n",
       "   hhs_geo_region_lrircsnp  hhs_geo_region_lzgpxyit  hhs_geo_region_mlyzmhmf  \\\n",
       "0                      0.0                      0.0                      1.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      1.0                      0.0                      0.0   \n",
       "3                      1.0                      0.0                      0.0   \n",
       "4                      0.0                      1.0                      0.0   \n",
       "\n",
       "   hhs_geo_region_oxchjgsf  hhs_geo_region_qufhixun  \\\n",
       "0                      0.0                      0.0   \n",
       "1                      0.0                      0.0   \n",
       "2                      0.0                      0.0   \n",
       "3                      0.0                      0.0   \n",
       "4                      0.0                      0.0   \n",
       "\n",
       "   census_msa_MSA, Not Principle  City  census_msa_MSA, Principle City  \\\n",
       "0                                  1.0                             0.0   \n",
       "1                                  0.0                             0.0   \n",
       "2                                  0.0                             0.0   \n",
       "3                                  1.0                             0.0   \n",
       "4                                  0.0                             0.0   \n",
       "\n",
       "   census_msa_Non-MSA  household_adults  household_children  \n",
       "0                 0.0               1.0                 0.0  \n",
       "1                 1.0               3.0                 0.0  \n",
       "2                 1.0               1.0                 0.0  \n",
       "3                 0.0               1.0                 0.0  \n",
       "4                 1.0               0.0                 1.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>h1n1_concern</th>\n",
       "      <th>h1n1_knowledge</th>\n",
       "      <th>opinion_h1n1_vacc_effective</th>\n",
       "      <th>opinion_h1n1_risk</th>\n",
       "      <th>opinion_h1n1_sick_from_vacc</th>\n",
       "      <th>opinion_seas_vacc_effective</th>\n",
       "      <th>opinion_seas_risk</th>\n",
       "      <th>opinion_seas_sick_from_vacc</th>\n",
       "      <th>age_group</th>\n",
       "      <th>education</th>\n",
       "      <th>...</th>\n",
       "      <th>hhs_geo_region_lrircsnp</th>\n",
       "      <th>hhs_geo_region_lzgpxyit</th>\n",
       "      <th>hhs_geo_region_mlyzmhmf</th>\n",
       "      <th>hhs_geo_region_oxchjgsf</th>\n",
       "      <th>hhs_geo_region_qufhixun</th>\n",
       "      <th>census_msa_MSA, Not Principle  City</th>\n",
       "      <th>census_msa_MSA, Principle City</th>\n",
       "      <th>census_msa_Non-MSA</th>\n",
       "      <th>household_adults</th>\n",
       "      <th>household_children</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   h1n1_concern  h1n1_knowledge  opinion_h1n1_vacc_effective  \\\n",
       "0           1.0             0.0                          3.0   \n",
       "1           3.0             2.0                          5.0   \n",
       "2           1.0             1.0                          3.0   \n",
       "3           1.0             1.0                          3.0   \n",
       "4           2.0             1.0                          3.0   \n",
       "\n",
       "   opinion_h1n1_risk  opinion_h1n1_sick_from_vacc  \\\n",
       "0                1.0                          2.0   \n",
       "1                4.0                          4.0   \n",
       "2                1.0                          1.0   \n",
       "3                3.0                          5.0   \n",
       "4                3.0                          2.0   \n",
       "\n",
       "   opinion_seas_vacc_effective  opinion_seas_risk  \\\n",
       "0                          2.0                1.0   \n",
       "1                          4.0                2.0   \n",
       "2                          4.0                1.0   \n",
       "3                          5.0                4.0   \n",
       "4                          3.0                1.0   \n",
       "\n",
       "   opinion_seas_sick_from_vacc  age_group  education  ...  \\\n",
       "0                          2.0        2.0        0.0  ...   \n",
       "1                          4.0        1.0        1.0  ...   \n",
       "2                          2.0        0.0        3.0  ...   \n",
       "3                          1.0        4.0        1.0  ...   \n",
       "4                          4.0        3.0        2.0  ...   \n",
       "\n",
       "   hhs_geo_region_lrircsnp  hhs_geo_region_lzgpxyit  hhs_geo_region_mlyzmhmf  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                      1.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   hhs_geo_region_oxchjgsf  hhs_geo_region_qufhixun  \\\n",
       "0                      1.0                      0.0   \n",
       "1                      0.0                      0.0   \n",
       "2                      0.0                      1.0   \n",
       "3                      0.0                      0.0   \n",
       "4                      0.0                      1.0   \n",
       "\n",
       "   census_msa_MSA, Not Principle  City  census_msa_MSA, Principle City  \\\n",
       "0                                  0.0                             0.0   \n",
       "1                                  1.0                             0.0   \n",
       "2                                  1.0                             0.0   \n",
       "3                                  0.0                             1.0   \n",
       "4                                  1.0                             0.0   \n",
       "\n",
       "   census_msa_Non-MSA  household_adults  household_children  \n",
       "0                 1.0               0.0                 0.0  \n",
       "1                 0.0               0.0                 0.0  \n",
       "2                 0.0               2.0                 0.0  \n",
       "3                 0.0               0.0                 0.0  \n",
       "4                 0.0               1.0                 0.0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de proceder, es necesario escalar los valores, sobre todo para que las variables de mayor rango (pertenencientes a las preguntas de opinión mayoritariamente) no influyan en el cálculo de las distancias con SVM. Dentro de las posibilidades de escalado, se puede optar por:\n",
    "- Normalización zero-mean: Escala los valores en un rango $[0,1]$ en función de la media y la varianza de la variable. Esta normalización se usa cuando las distribuciones de las variables siguen aproximadamente una distribución normal.\n",
    "- Normalización MinMaxScaling: Escala los valores en un rango $[0,1]$ en función de los valores máximos y mínimos de cada variable. Esta técnica de escalado conserva las características de los datos originales tras la transformación. \n",
    "\n",
    "Dado que no se conocen las distribuciones originales de los datos, se va a optar por el uso de escalado MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 1.        , 1.        , ..., 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.33333333, 0.5       , 0.75      , ..., 1.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.66666667, 1.        , 1.        , ..., 1.        , 0.33333333,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.5       , 0.75      , ..., 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [1.        , 0.5       , 0.25      , ..., 0.        , 0.33333333,\n",
       "        0.        ],\n",
       "       [0.66666667, 0.5       , 1.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escalar características\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que todos los valores sean numéricos\n",
    "#X_train = X_train.astype(float)\n",
    "#X_test = X_test.astype(float)\n",
    "y_train = y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_split, X_valid_split, y_train_split, y_valid_split = train_test_split(\n",
    "    X_train_scaled, y_train, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos todos los datos en el mismo formato, podemos pasar a implementar SVM. Este algoritmo trata de sobredimensionar los datos para poder generar un hiperplano de separación entre dos clases, por lo que, de manera nativa no es capaz de realizar una clasificación multietiqueta. Para solventar este problema se usa un pequeño 'truco' a la hora de implementar el algoritmo, que es la descomposición binaria de la respuesta obtenida, de esta manera SVM puede abordar los problemas multietiqueta como problemas independientes:\n",
    "\n",
    "- Si se entrena un clasificador para cada par de valores posibles se está usando una estrategia OVO (One-vs-One)\n",
    "- Si el clasificador es capaz de distinguir en cada caso su etiqueta frente a las demás se usa una estrategia OVR (One-vs-Rest)\n",
    "\n",
    "Otra opción para la clasificación multietiqueta pasa por el uso de la función 'MultiOutputClassifier' implementada en 'sklearn', capaz de tratar cada etiqueta como un problema binario independiente, entrenando un clasificador para cada etiqueta sin comparar con las demás:\n",
    "\n",
    "\n",
    "#### Clasificación SVM con RBF y balanceo de clases\n",
    "\n",
    "##### Optimización por GridSearch y clases balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros encontrados:  {'estimator__C': 1, 'estimator__gamma': 'auto', 'estimator__kernel': 'rbf', 'estimator__max_iter': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.6356932153392331\n",
      "ROC AUC Score en optimización (train): 0.8374914602749269\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.58      1868\n",
      "           1       0.75      0.78      0.76      4044\n",
      "\n",
      "   micro avg       0.64      0.76      0.69      5912\n",
      "   macro avg       0.62      0.74      0.67      5912\n",
      "weighted avg       0.66      0.76      0.70      5912\n",
      " samples avg       0.35      0.37      0.35      5912\n",
      "\n",
      "ROC AUC Score (test): 0.7651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000, class_weight='balanced')\n",
    "\n",
    "# Paso 2: Configurar MultiOutputClassifier para manejar multietiqueta\n",
    "multi_label_svm = MultiOutputClassifier(base_svm)\n",
    "\n",
    "# Paso 3: Definir el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],       # Regularización\n",
    "    'gamma': ['scale', 'auto'],   # Parámetro del kernel RBF\n",
    "    'max_iter': [10000, 50000, 100000],\n",
    "    'kernel': ['rbf', 'precomputed']\n",
    "}\n",
    "\n",
    "# Paso 4: Configurar GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=multi_label_svm,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # Validación cruzada de 5 pliegues\n",
    "    scoring='roc_auc',  # Métrica para evaluar el modelo\n",
    "    verbose=3,  # Para ver el progreso\n",
    "    n_jobs=-1,   # Usar todos los núcleos disponibles\n",
    "    refit=True\n",
    "\n",
    ")\n",
    "\n",
    "# Paso 5: Entrenar con los datos de entrenamiento\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Paso 6: Resultados\n",
    "print(\"Mejores parámetros encontrados: \", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train_split, y_train_split)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(X_valid_split)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en optimización (train): {grid_search.best_score_}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_valid_split, y_valid_pred, zero_division=0))\n",
    "roc_auc = roc_auc_score(y_valid_split, y_valid_pred, average='macro', multi_class='ovr')\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(f\"ROC AUC Score (test): {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimización de parámetros con RandomSearch y clases balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'estimator__max_iter': 10000, 'estimator__gamma': 'auto', 'estimator__C': np.float64(1.0)}\n",
      "Mejor score en train: 0.8370122504743737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.6356932153392331\n",
      "ROC AUC Score en Test: 0.7651\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.71      0.58      1868\n",
      "           1       0.75      0.78      0.76      4044\n",
      "\n",
      "   micro avg       0.64      0.76      0.69      5912\n",
      "   macro avg       0.62      0.74      0.67      5912\n",
      "weighted avg       0.66      0.76      0.70      5912\n",
      " samples avg       0.35      0.37      0.35      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000, class_weight='balanced')\n",
    "\n",
    "# Configurar MultiOutputClassifier\n",
    "multi_label_svm = MultiOutputClassifier(base_svm)\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'estimator__C': np.logspace(-3, 1, 5),  # Ajuste más fino para 'C'\n",
    "    'estimator__gamma': [\"scale\", \"auto\"],  # Combina números y strings válidos\n",
    "    'estimator__max_iter': [10000, 50000, 100000],\n",
    "    'estimator__kernel': ['rbf', 'precomputed']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    multi_label_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train_split, y_train_split)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_valid_split, y_valid_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De aquí en adelante usaremos la optimización por Random search por ser más efectiva en el cálculo.\n",
    "\n",
    "#### SVM RBF con clases Desbalanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'estimator__max_iter': 50000, 'estimator__gamma': np.float64(0.01), 'estimator__C': np.float64(10.0)}\n",
      "Mejor score en train: 0.8348147868911259\n",
      "Accuracy en validación: 0.6655321080099841\n",
      "ROC AUC Score en Test: 0.7203\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.38      0.49      1868\n",
      "           1       0.77      0.73      0.75      4044\n",
      "\n",
      "   micro avg       0.75      0.62      0.68      5912\n",
      "   macro avg       0.73      0.55      0.62      5912\n",
      "weighted avg       0.75      0.62      0.67      5912\n",
      " samples avg       0.33      0.31      0.31      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000)\n",
    "\n",
    "# Configurar MultiOutputClassifier\n",
    "multi_label_svm = MultiOutputClassifier(base_svm)\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'estimator__C': np.logspace(-3, 1, 5),  # Ajuste más fino para 'C'\n",
    "    'estimator__gamma': np.logspace(-3, 1, 5),  # Ajuste más fino para 'gamma'\n",
    "    'estimator__max_iter': [10000, 50000],\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    multi_label_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train_split, y_train_split)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_valid_split, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Kernel Lineal y Balanceo de Clases\n",
    "\n",
    "También podemos probar LinearSVC, en este caso el clasificador SVM que se usa kernel lineal y al no obtener probabilidades, no podemos calcular el roc_auc para evaluar el randomsearch:\n",
    "\n",
    "\n",
    "Con balanceo de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'estimator__tol': 0.001, 'estimator__max_iter': 10000, 'estimator__dual': True, 'estimator__C': 0.1}\n",
      "Accuracy en validación: 0.6371681415929203\n",
      "ROC AUC Score en Test: 0.7648\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.71      0.58      1868\n",
      "           1       0.76      0.76      0.76      4044\n",
      "\n",
      "   micro avg       0.65      0.74      0.69      5912\n",
      "   macro avg       0.62      0.73      0.67      5912\n",
      "weighted avg       0.67      0.74      0.70      5912\n",
      " samples avg       0.34      0.37      0.34      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "multi_label_lsvm = MultiOutputClassifier(LinearSVC(C=1.0, random_state=42, dual=True, max_iter=10000, class_weight='balanced'))\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'estimator__C': [0.01, 0.1, 1, 10],  # Valores discretos para C\n",
    "    'estimator__tol': [ 1e-3, 1e-2],  # Tolerancia fija en valores comunes\n",
    "    'estimator__max_iter': [10000, 20000, 50000],  # Opciones discretas\n",
    "    'estimator__dual': [True, False]  # Opciones binarias\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    multi_label_lsvm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='accuracy',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train_split, y_train_split)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_valid_split, y_valid_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6556198980227645)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo,..................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM Kernel Lineal y Desbalanceo de Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'estimator__tol': 0.01, 'estimator__max_iter': 20000, 'estimator__dual': True, 'estimator__C': 1}\n",
      "Accuracy en validación: 0.6675743135920127\n",
      "ROC AUC Score en Test: 0.7241\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.40      0.50      1868\n",
      "           1       0.77      0.73      0.75      4044\n",
      "\n",
      "   micro avg       0.75      0.63      0.68      5912\n",
      "   macro avg       0.73      0.56      0.63      5912\n",
      "weighted avg       0.74      0.63      0.67      5912\n",
      " samples avg       0.34      0.32      0.32      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "multi_label_lsvm = MultiOutputClassifier(LinearSVC(C=1.0, random_state=42, dual=True, max_iter=10000))\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'estimator__C': [0.01, 0.1, 1, 10],  # Valores discretos para C\n",
    "    'estimator__tol': [ 1e-3, 1e-2],  # Tolerancia fija en valores comunes\n",
    "    'estimator__max_iter': [10000, 20000, 50000],  # Opciones discretas\n",
    "    'estimator__dual': [True, False]  # Opciones binarias\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    multi_label_lsvm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='accuracy',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(X_train_split, y_train_split)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_valid_split, y_valid_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.6556198980227645)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Vs One y One vs Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparamos los resultados con los que se obtienen a partir de OVO y OVR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.6371681415929203\n",
      "ROC AUC Score: 0.7648\n",
      "Reporte de clasificación OVR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.71      0.58      1868\n",
      "           1       0.76      0.76      0.76      4044\n",
      "\n",
      "   micro avg       0.65      0.74      0.69      5912\n",
      "   macro avg       0.62      0.73      0.67      5912\n",
      "weighted avg       0.67      0.74      0.70      5912\n",
      " samples avg       0.34      0.37      0.34      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "\n",
    "ovr = OneVsRestClassifier(LinearSVC(C=0.1, random_state=42, dual=True, max_iter=10000, class_weight='balanced', tol= 0.001)); # Usamos mismos parámetros que antes y la misma semilla\n",
    "ovr.fit(X_train_split, y_train_split)\n",
    "y_pred = ovr.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación OVR:\\n\", classification_report(y_valid_split, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.6345586566825505\n",
      "ROC AUC Score: 0.7631\n",
      "Reporte de clasificación OVR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.70      0.57      1868\n",
      "           1       0.75      0.77      0.76      4044\n",
      "\n",
      "   micro avg       0.65      0.75      0.69      5912\n",
      "   macro avg       0.62      0.73      0.67      5912\n",
      "weighted avg       0.67      0.75      0.70      5912\n",
      " samples avg       0.35      0.37      0.35      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovr = OneVsRestClassifier(SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000, class_weight='balanced', C=10, gamma=0.01)); # Usamos mismos parámetros que antes y la misma semilla\n",
    "ovr.fit(X_train_split, y_train_split)\n",
    "y_pred = ovr.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación OVR:\\n\", classification_report(y_valid_split, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.6345586566825505\n",
      "ROC AUC Score: 0.7631\n",
      "Reporte de clasificación OVR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.70      0.57      1868\n",
      "           1       0.75      0.77      0.76      4044\n",
      "\n",
      "   micro avg       0.65      0.75      0.69      5912\n",
      "   macro avg       0.62      0.73      0.67      5912\n",
      "weighted avg       0.67      0.75      0.70      5912\n",
      " samples avg       0.35      0.37      0.35      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovo = OneVsOneClassifier(LinearSVC(C=0.1, random_state=42, dual=True, max_iter=10000, class_weight='balanced', tol= 0.001)); # Usamos mismos parámetros que antes y la misma semilla\n",
    "ovr.fit(X_train_split, y_train_split)\n",
    "y_pred = ovr.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación OVR:\\n\", classification_report(y_valid_split, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.6345586566825505\n",
      "ROC AUC Score: 0.7631\n",
      "Reporte de clasificación OVR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.70      0.57      1868\n",
      "           1       0.75      0.77      0.76      4044\n",
      "\n",
      "   micro avg       0.65      0.75      0.69      5912\n",
      "   macro avg       0.62      0.73      0.67      5912\n",
      "weighted avg       0.67      0.75      0.70      5912\n",
      " samples avg       0.35      0.37      0.35      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovr =MultiOutputClassifier(OneVsOneClassifier(SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000, class_weight='balanced', C=10, gamma=0.01))); # Usamos mismos parámetros que antes y la misma semilla\n",
    "ovr.fit(X_train_split, y_train_split)\n",
    "y_pred = ovr.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación OVR:\\n\", classification_report(y_valid_split, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.6371681415929203\n",
      "ROC AUC Score: 0.7648\n",
      "Reporte de clasificación OVR:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.71      0.58      1868\n",
      "           1       0.76      0.76      0.76      4044\n",
      "\n",
      "   micro avg       0.65      0.74      0.69      5912\n",
      "   macro avg       0.62      0.73      0.67      5912\n",
      "weighted avg       0.67      0.74      0.70      5912\n",
      " samples avg       0.34      0.37      0.34      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ovo =MultiOutputClassifier( OneVsOneClassifier(LinearSVC(C=0.1, random_state=42, dual=True, max_iter=10000, class_weight='balanced', tol= 0.001))); # Usamos mismos parámetros que antes y la misma semilla\n",
    "ovo.fit(X_train_split, y_train_split)\n",
    "y_pred = ovo.predict(X_valid_split)\n",
    "roc_auc = roc_auc_score(y_valid_split, y_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_valid_split, y_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación OVR:\\n\", classification_report(y_valid_split, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece claro que el método OVR con LinearSVC se acerca en mayor medida a nuestros resultados con MultiOutputClassifier. \n",
    "\n",
    "#### Simplificación del Problema\n",
    "\n",
    "Como hemos mencionado anteriormente, SVM no trabaja directamente con problemas multietiqueta, por lo que se envuelve con MultiOutputClassifier. Otra opción válida es dividir inicialmente las etiquetas para descomponerlo en dos SVM distintos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "respondent_id\n",
       "24706    0\n",
       "5393     0\n",
       "20898    1\n",
       "3429     0\n",
       "8731     0\n",
       "        ..\n",
       "21575    0\n",
       "5390     0\n",
       "860      0\n",
       "15795    0\n",
       "23654    0\n",
       "Name: h1n1_vaccine, Length: 21365, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y_train[\"seasonal_vaccine\"]\n",
    "z=y_train[\"h1n1_vaccine\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vacuna estacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_train_scaled,y,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_iter': 10000, 'gamma': np.float64(0.01), 'C': np.float64(10.0)}\n",
      "Mejor score en train: 0.8463056572303893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.7744290527892175\n",
      "ROC AUC Score en Test: 0.7762\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.76      0.78      2891\n",
      "           1       0.73      0.80      0.76      2451\n",
      "\n",
      "    accuracy                           0.77      5342\n",
      "   macro avg       0.77      0.78      0.77      5342\n",
      "weighted avg       0.78      0.77      0.77      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000, class_weight='balanced')\n",
    "\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': np.logspace(-2, 1, 4),        # Rango reducido para 'C'\n",
    "    'gamma': np.logspace(-2, 1, 4),    # Rango reducido para 'gamma'\n",
    "    'max_iter': [10000, 50000],        # Iteraciones máximas\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sin balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'max_iter': 10000, 'gamma': np.float64(0.01), 'C': np.float64(10.0)}\n",
      "Mejor score en train: 0.8461012794615804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy en validación: 0.7796705353800075\n",
      "ROC AUC Score en Test: 0.7766\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      2891\n",
      "           1       0.77      0.74      0.75      2451\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.78      0.78      0.78      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000)\n",
    "\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': np.logspace(-2, 1, 4),        # Rango reducido para 'C'\n",
    "    'gamma': np.logspace(-2, 1, 4),    # Rango reducido para 'gamma'\n",
    "    'max_iter': [10000, 50000],        # Iteraciones máximas\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVM con balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'tol': 0.01, 'max_iter': 20000, 'dual': True, 'C': 1}\n",
      "Mejor score en train: 0.8428105823411389\n",
      "Accuracy en validación: 0.775926619243729\n",
      "ROC AUC Score en Test: 0.7747\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79      2891\n",
      "           1       0.75      0.76      0.76      2451\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.77      0.77      0.77      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm =LinearSVC(C=1.0, random_state=42, dual=True, max_iter=10000, class_weight='balanced')\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Valores discretos para C\n",
    "    'tol': [ 1e-3, 1e-2],  # Tolerancia fija en valores comunes\n",
    "    'max_iter': [10000, 20000, 50000],  # Opciones discretas\n",
    "    'dual': [True, False]  # Opciones binarias\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVM Sin balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'tol': 0.01, 'max_iter': 10000, 'dual': True, 'C': 10}\n",
      "Mejor score en train: 0.8428026594336577\n",
      "Accuracy en validación: 0.7755522276301011\n",
      "ROC AUC Score en Test: 0.7723\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.80      2891\n",
      "           1       0.77      0.73      0.75      2451\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.77      0.77      0.77      5342\n",
      "weighted avg       0.78      0.78      0.78      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm =LinearSVC(C=1.0, random_state=42, dual=True, max_iter=10000)\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Valores discretos para C\n",
    "    'tol': [ 1e-3, 1e-2],  # Tolerancia fija en valores comunes\n",
    "    'max_iter': [10000, 20000, 50000],  # Opciones discretas\n",
    "    'dual': [True, False]  # Opciones binarias\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vacuna H1N1. Clases balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_train_scaled,z,random_state=42,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'max_iter': 50000, 'gamma': np.float64(0.01), 'C': np.float64(10.0)}\n",
      "Mejor score en train: 0.829500864916958\n",
      "Accuracy en validación: 0.7832272557094722\n",
      "ROC AUC Score en Test: 0.7512\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.85      4212\n",
      "           1       0.49      0.70      0.58      1130\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.70      0.75      0.72      5342\n",
      "weighted avg       0.82      0.78      0.80      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000, class_weight='balanced')\n",
    "\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': np.logspace(-2, 1, 4),        # Rango reducido para 'C'\n",
    "    'gamma': np.logspace(-2, 1, 4),    # Rango reducido para 'gamma'\n",
    "    'max_iter': [10000, 50000],        # Iteraciones máximas\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sin balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'max_iter': 50000, 'gamma': np.float64(0.01), 'C': np.float64(1.0)}\n",
      "Mejor score en train: 0.8239213951879351\n",
      "Accuracy en validación: 0.8335829277424186\n",
      "ROC AUC Score en Test: 0.6746\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.95      0.90      4212\n",
      "           1       0.68      0.40      0.50      1130\n",
      "\n",
      "    accuracy                           0.83      5342\n",
      "   macro avg       0.77      0.67      0.70      5342\n",
      "weighted avg       0.82      0.83      0.82      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm = SVC(kernel='rbf', probability=True, random_state=42, max_iter=10000)\n",
    "\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': np.logspace(-2, 1, 4),        # Rango reducido para 'C'\n",
    "    'gamma': np.logspace(-2, 1, 4),    # Rango reducido para 'gamma'\n",
    "    'max_iter': [10000, 50000],        # Iteraciones máximas\n",
    "}\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC balanceado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'tol': 0.001, 'max_iter': 20000, 'dual': True, 'C': 1}\n",
      "Mejor score en train: 0.8277192999254049\n",
      "Accuracy en validación: 0.7806065144140771\n",
      "ROC AUC Score en Test: 0.7527\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.80      0.85      4212\n",
      "           1       0.49      0.70      0.58      1130\n",
      "\n",
      "    accuracy                           0.78      5342\n",
      "   macro avg       0.70      0.75      0.71      5342\n",
      "weighted avg       0.82      0.78      0.79      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm =LinearSVC(C=1.0, random_state=42, dual=True, max_iter=10000, class_weight='balanced')\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Valores discretos para C\n",
    "    'tol': [ 1e-3, 1e-2],  # Tolerancia fija en valores comunes\n",
    "    'max_iter': [10000, 20000, 50000],  # Opciones discretas\n",
    "    'dual': [True, False]  # Opciones binarias\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sin Balanceo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Mejores parámetros: {'tol': 0.001, 'max_iter': 50000, 'dual': True, 'C': 10}\n",
      "Mejor score en train: 0.8271237574013132\n",
      "Accuracy en validación: 0.8367652564582553\n",
      "ROC AUC Score en Test: 0.6770\n",
      "Reporte de clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      4212\n",
      "           1       0.70      0.40      0.51      1130\n",
      "\n",
      "    accuracy                           0.84      5342\n",
      "   macro avg       0.78      0.68      0.71      5342\n",
      "weighted avg       0.82      0.84      0.82      5342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Definir el modelo base\n",
    "base_svm =LinearSVC(C=1.0, random_state=42, dual=True, max_iter=10000)\n",
    "\n",
    "# Definir el espacio de búsqueda de parámetros\n",
    "param_dist = {\n",
    "    'C': [0.01, 0.1, 1, 10],  # Valores discretos para C\n",
    "    'tol': [ 1e-3, 1e-2],  # Tolerancia fija en valores comunes\n",
    "    'max_iter': [10000, 20000, 50000],  # Opciones discretas\n",
    "    'dual': [True, False]  # Opciones binarias\n",
    "}\n",
    "\n",
    "\n",
    "# Configurar RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_svm,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,  # Número de iteraciones aleatorias\n",
    "    cv=3,       # Validación cruzada\n",
    "    scoring='roc_auc',  # Métrica de evaluación\n",
    "    n_jobs=-1,  # Usar todos los núcleos disponibles\n",
    "    verbose=3,  # Progreso\n",
    "    random_state=42,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "# Ejecutar RandomizedSearchCV\n",
    "random_search.fit(x_train, y_train)\n",
    "\n",
    "# Imprimir los mejores parámetros y el score\n",
    "print(\"Mejores parámetros:\", random_search.best_params_)\n",
    "print(\"Mejor score en train:\", random_search.best_score_)\n",
    "\n",
    "\n",
    "# Ajustamos el modelo y lo evaluamos\n",
    "best_model = random_search.best_estimator_\n",
    "best_model.fit(x_train, y_train)\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "\n",
    "y_valid_pred = best_model.predict(x_test)\n",
    "roc_auc = roc_auc_score(y_test, y_valid_pred)\n",
    "\n",
    "print(\"Accuracy en validación:\", accuracy_score(y_test, y_valid_pred))\n",
    "# Imprimir el roc_auc_score global\n",
    "print(f\"ROC AUC Score en Test: {roc_auc:.4f}\")\n",
    "print(\"Reporte de clasificación:\\n\", classification_report(y_test, y_valid_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles\n",
    "\n",
    "\n",
    "### Para LinearSVM con Balanceo entre clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bagging_SVM ===\n",
      "Accuracy: 0.6671204901293397\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.40      0.51      1868\n",
      "           1       0.77      0.73      0.75      4044\n",
      "\n",
      "   micro avg       0.75      0.63      0.68      5912\n",
      "   macro avg       0.73      0.57      0.63      5912\n",
      "weighted avg       0.74      0.63      0.67      5912\n",
      " samples avg       0.34      0.32      0.32      5912\n",
      "\n",
      "=== Random_Subspaces ===\n",
      "Accuracy: 0.6277513047424552\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.13      0.22      1868\n",
      "           1       0.77      0.69      0.73      4044\n",
      "\n",
      "   micro avg       0.78      0.51      0.62      5912\n",
      "   macro avg       0.79      0.41      0.47      5912\n",
      "weighted avg       0.79      0.51      0.57      5912\n",
      " samples avg       0.31      0.26      0.28      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "# 1. Modelo base SVM con MultiOutputClassifier para multietiqueta\n",
    "base_svm = LinearSVC(C=0.1, random_state=42, dual=True, max_iter=10000, tol=0.001, class_weight='balanced')\n",
    "\n",
    "# 2. Bagging clásico con SVM\n",
    "bagging_svm = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=10,  # 10 modelos base\n",
    "    max_samples=0.8,   # Usa el 80% de las muestras\n",
    "    max_features=1.0,  # Usa el 100% de las características\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "# Envolvemos el bagging con MultiOutputClassifier\n",
    "bagging_svm_multi = MultiOutputClassifier(bagging_svm)\n",
    "\n",
    "\n",
    "# 3. Random Subspaces (Bagging con muestreo de características)\n",
    "random_subspaces = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=10,  # 10 modelos base\n",
    "    max_samples=1.0,   # Usa el 100% de las muestras\n",
    "    max_features=0.5,  # Usa el 50% de las características\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "# Envolvemos el Random Subspaces con MultiOutputClassifier\n",
    "random_subspaces_multi = MultiOutputClassifier(random_subspaces)\n",
    "\n",
    "# Lista de modelos para comparar\n",
    "models = {\n",
    "    \"Bagging_SVM\": bagging_svm_multi,\n",
    "    \"Random_Subspaces\": random_subspaces_multi\n",
    "}\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "\n",
    "    # Predicción\n",
    "    y_pred = model.predict(X_valid_split)\n",
    "\n",
    "    # Métricas\n",
    "    accuracy = accuracy_score(y_valid_split, y_pred)\n",
    "    report = classification_report(y_valid_split, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_valid_split, y_pred)\n",
    "\n",
    "    # Guardar resultados\n",
    "    results[name] = {\"accuracy\": accuracy, \"report\": report}\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble de SVM con kernel RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Bagging_SVM ===\n",
      "Accuracy: 0.6418198320853188\n",
      "Roc-AUC: 0.7642296571868485\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.70      0.58      1868\n",
      "           1       0.76      0.75      0.76      4044\n",
      "\n",
      "   micro avg       0.66      0.74      0.69      5912\n",
      "   macro avg       0.63      0.72      0.67      5912\n",
      "weighted avg       0.68      0.74      0.70      5912\n",
      " samples avg       0.34      0.36      0.34      5912\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\er_ja\\anaconda3\\envs\\Python\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random_Subspaces ===\n",
      "Accuracy: 0.47674154753800774\n",
      "Roc-AUC: 0.7226042099584467\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.88      0.47      1868\n",
      "           1       0.70      0.81      0.75      4044\n",
      "\n",
      "   micro avg       0.50      0.83      0.62      5912\n",
      "   macro avg       0.51      0.84      0.61      5912\n",
      "weighted avg       0.58      0.83      0.66      5912\n",
      " samples avg       0.33      0.41      0.35      5912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Modelo base SVM con MultiOutputClassifier para multietiqueta\n",
    "base_svm = SVC(kernel='rbf', C=10, random_state=42,  max_iter=10000, gamma=0.01, class_weight='balanced')\n",
    "\n",
    "# 2. Bagging clásico con SVM\n",
    "bagging_svm = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=10,  # 10 modelos base\n",
    "    max_samples=0.8,   # Usa el 80% de las muestras\n",
    "    max_features=1.0,  # Usa el 100% de las características\n",
    "    bootstrap=True,\n",
    "    random_state=42\n",
    ")\n",
    "# Envolvemos el bagging con MultiOutputClassifier\n",
    "bagging_svm_multi = MultiOutputClassifier(bagging_svm)\n",
    "\n",
    "\n",
    "# 3. Random Subspaces (Bagging con muestreo de características)\n",
    "random_subspaces = BaggingClassifier(\n",
    "    estimator=base_svm,\n",
    "    n_estimators=10,  # 10 modelos base\n",
    "    max_samples=1.0,   # Usa el 100% de las muestras\n",
    "    max_features=0.5,  # Usa el 50% de las características\n",
    "    bootstrap=False,\n",
    "    random_state=42\n",
    ")\n",
    "# Envolvemos el Random Subspaces con MultiOutputClassifier\n",
    "random_subspaces_multi = MultiOutputClassifier(random_subspaces)\n",
    "\n",
    "# Lista de modelos para comparar\n",
    "models = {\n",
    "    \"Bagging_SVM\": bagging_svm_multi,\n",
    "    \"Random_Subspaces\": random_subspaces_multi\n",
    "}\n",
    "\n",
    "# Entrenamiento y evaluación\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    # Entrenar el modelo\n",
    "    model.fit(X_train_split, y_train_split)\n",
    "\n",
    "    # Predicción\n",
    "    y_pred = model.predict(X_valid_split)\n",
    "\n",
    "    # Métricas\n",
    "    accuracy = accuracy_score(y_valid_split, y_pred)\n",
    "    report = classification_report(y_valid_split, y_pred, zero_division=0)\n",
    "    roc_auc = roc_auc_score(y_valid_split, y_pred)\n",
    "\n",
    "    # Guardar resultados\n",
    "    results[name] = {\"accuracy\": accuracy, \"roc_auc\":roc_auc , \"report\": report}\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Roc-AUC: {roc_auc}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
